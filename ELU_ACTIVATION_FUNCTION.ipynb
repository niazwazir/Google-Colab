{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SRCNN_KERAS_IN_Python3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCnEnF6C893d",
        "outputId": "2271e666-f67c-4ee5-dd48-6cca3c5cb3ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#HOW TO SOLVE THE Scipy ERROR IN PYTHON 3, SEE ON CELL NO 7 SOLUTION\n",
        "!git clone https://github.com/niazwazir/SRCNN-Keras.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SRCNN-Keras'...\n",
            "remote: Enumerating objects: 99, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 99 (delta 7), reused 0 (delta 0), pack-reused 72\u001b[K\n",
            "Unpacking objects: 100% (99/99), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W21GbOHz9C0f",
        "outputId": "e41cd565-00e7-4037-946d-2a8f717bf99e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  SRCNN-Keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6qIG14V9Fk7",
        "outputId": "f7349519-bd24-43d3-a0a9-c57fa63c5f60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cd SRCNN-Keras"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SRCNN-Keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6OwpQR-9F0u",
        "outputId": "9c740e12-e690-447d-9a87-30423bf2c59d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "baby_GT.bmp\n",
            "baby_x2_GT.png\n",
            "bird_GT.bmp\n",
            "Brain.jpg\n",
            "butterfly_GT.bmp\n",
            "head_GT.bmp\n",
            "Image_Super_Resolution.ipynb\n",
            "MOUNT_SRCNN_37_PSNR.ipynb\n",
            "prepare_data.py\n",
            "project.gif\n",
            "PSNR_SSIM_MSE_SRCNN_Super_Resolution_.ipynb\n",
            "Set5\n",
            "SRCNN_COLOR_IMAGE_GENERATED.ipynb\n",
            "SRCNN_KERAS_2nd.ipynb\n",
            "SRCNN_KERAS_IN_Python3_Curves.ipynb\n",
            "SRCNN_KERAS_IN_Python3.ipynb\n",
            "SRCNN_KERAS.ipynb\n",
            "SRCNNMODIFIEDPYTHON2.ipynb\n",
            "subpixel.py\n",
            "text\n",
            "woman_GT.bmp\n",
            "yang91.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zghv-gAj9LsB",
        "outputId": "e47c8a31-d785-474a-a52f-69f6ec80e1c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!unzip yang91.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  yang91.zip\n",
            "   creating: yang91/\n",
            "  inflating: yang91/tt9.bmp          \n",
            "  inflating: yang91/tt8.bmp          \n",
            "  inflating: yang91/tt7.bmp          \n",
            "  inflating: yang91/tt6.bmp          \n",
            "  inflating: yang91/tt5.bmp          \n",
            "  inflating: yang91/tt4.bmp          \n",
            "  inflating: yang91/tt3.bmp          \n",
            "  inflating: yang91/tt27.bmp         \n",
            "  inflating: yang91/tt26.bmp         \n",
            "  inflating: yang91/tt25.bmp         \n",
            "  inflating: yang91/tt24.bmp         \n",
            "  inflating: yang91/tt23.bmp         \n",
            "  inflating: yang91/tt22.bmp         \n",
            "  inflating: yang91/tt21.bmp         \n",
            "  inflating: yang91/tt20.bmp         \n",
            "  inflating: yang91/tt2.bmp          \n",
            "  inflating: yang91/tt19.bmp         \n",
            "  inflating: yang91/tt18.bmp         \n",
            "  inflating: yang91/tt17.bmp         \n",
            "  inflating: yang91/tt16.bmp         \n",
            "  inflating: yang91/tt15.bmp         \n",
            "  inflating: yang91/tt14.bmp         \n",
            "  inflating: yang91/tt13.bmp         \n",
            "  inflating: yang91/tt12.bmp         \n",
            "  inflating: yang91/tt10.bmp         \n",
            "  inflating: yang91/tt1.bmp          \n",
            "  inflating: yang91/t66.bmp          \n",
            "  inflating: yang91/t65.bmp          \n",
            "  inflating: yang91/t64.bmp          \n",
            "  inflating: yang91/t63.bmp          \n",
            "  inflating: yang91/t62.bmp          \n",
            "  inflating: yang91/t61.bmp          \n",
            "  inflating: yang91/t60.bmp          \n",
            "  inflating: yang91/t59.bmp          \n",
            "  inflating: yang91/t58.bmp          \n",
            "  inflating: yang91/t57.bmp          \n",
            "  inflating: yang91/t56.bmp          \n",
            "  inflating: yang91/t55.bmp          \n",
            "  inflating: yang91/t54.bmp          \n",
            "  inflating: yang91/t53.bmp          \n",
            "  inflating: yang91/t52.bmp          \n",
            "  inflating: yang91/t51.bmp          \n",
            "  inflating: yang91/t50.bmp          \n",
            "  inflating: yang91/t49.bmp          \n",
            "  inflating: yang91/t48.bmp          \n",
            "  inflating: yang91/t47.bmp          \n",
            "  inflating: yang91/t46.bmp          \n",
            "  inflating: yang91/t45.bmp          \n",
            "  inflating: yang91/t44.bmp          \n",
            "  inflating: yang91/t43.bmp          \n",
            "  inflating: yang91/t42.bmp          \n",
            "  inflating: yang91/t40.bmp          \n",
            "  inflating: yang91/t39.bmp          \n",
            "  inflating: yang91/t38.bmp          \n",
            "  inflating: yang91/t37.bmp          \n",
            "  inflating: yang91/t36.bmp          \n",
            "  inflating: yang91/t35.bmp          \n",
            "  inflating: yang91/t34.bmp          \n",
            "  inflating: yang91/t33.bmp          \n",
            "  inflating: yang91/t32.bmp          \n",
            "  inflating: yang91/t31.bmp          \n",
            "  inflating: yang91/t30.bmp          \n",
            "  inflating: yang91/t29.bmp          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kWtopH3XKDB",
        "outputId": "372183f0-35fb-40c2-e571-b9b9ab35c881",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip uninstall scipy"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: scipy 1.4.1\n",
            "Uninstalling scipy-1.4.1:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/scipy-1.4.1.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/scipy/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled scipy-1.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8zPf00DXUHn",
        "outputId": "e9027c8d-4285-4d2a-c156-f96a21170377",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install scipy==1.1.0"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scipy==1.1.0\n",
            "  Downloading scipy-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (31.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2 MB 189 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.1.0) (1.21.5)\n",
            "Installing collected packages: scipy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pymc3 3.11.4 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n",
            "plotnine 0.6.0 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n",
            "jax 0.3.4 requires scipy>=1.2.1, but you have scipy 1.1.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed scipy-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn6WL_nG8qSm"
      },
      "source": [
        "import keras.backend as K\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Conv2D, Activation, Input\n",
        "from keras import optimizers\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "import scipy.misc\n",
        "import scipy.ndimage\n",
        "import cv2\n",
        "import math\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import tensorflow"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSUGxzPH2gny",
        "outputId": "2235d227-60ac-4434-bb94-5fae535e2d16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "img_shape = (32,32,1)\n",
        "input_img = Input(shape=(img_shape))\n",
        "C1 = Conv2D(64,(9,9),padding='SAME',name='CONV1')(input_img)\n",
        "A1 = Activation('elu', name='act1')(C1)\n",
        "C2 = Conv2D(32,(1,1),padding='SAME',name='CONV2')(A1)\n",
        "A2 = Activation('elu', name='act2')(C2)\n",
        "C3 = Conv2D(1,(5,5),padding='SAME',name='CONV3')(A2)\n",
        "A3 = Activation('elu', name='act3')(C3)\n",
        "model = Model(input_img, A3)\n",
        "opt = tensorflow.keras.optimizers.Adam(lr=0.0003)\n",
        "model.compile(optimizer=opt,loss='mean_squared_error')\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 32, 32, 1)]       0         \n",
            "                                                                 \n",
            " CONV1 (Conv2D)              (None, 32, 32, 64)        5248      \n",
            "                                                                 \n",
            " act1 (Activation)           (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " CONV2 (Conv2D)              (None, 32, 32, 32)        2080      \n",
            "                                                                 \n",
            " act2 (Activation)           (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " CONV3 (Conv2D)              (None, 32, 32, 1)         801       \n",
            "                                                                 \n",
            " act3 (Activation)           (None, 32, 32, 1)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,129\n",
            "Trainable params: 8,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "HafFlv2ogR7q"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_mXrbPBTNNi",
        "outputId": "cfd58d6c-17a2-4383-cdba-6e28228e6675",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    model, to_file='model.png', show_shapes=False, show_layer_names=True, rankdir='LR', expand_nested=False, dpi=96\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTD4xr9i2sjV"
      },
      "source": [
        "def modcrop(image, scale=2): #BY DEFAULT SCALE 2\n",
        "    if len(image.shape) == 3:\n",
        "        h, w, _ = image.shape\n",
        "        h = h - np.mod(h, scale)\n",
        "        w = w - np.mod(w, scale)\n",
        "        image = image[0:h, 0:w, :]\n",
        "    else:\n",
        "        h, w = image.shape\n",
        "        h = h - np.mod(h, scale)\n",
        "        w = w - np.mod(w, scale)\n",
        "        image = image[0:h, 0:w]\n",
        "    return image"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftL-zZ4A2w7j"
      },
      "source": [
        "def create_LR(image,scale):\n",
        "    label_ = modcrop(image, scale)\n",
        "    label_ = label_ / 255.\n",
        "    input_ = scipy.ndimage.interpolation.zoom(label_, (1./scale), prefilter=False)\n",
        "    input_ = scipy.ndimage.interpolation.zoom(input_, (scale/1.), prefilter=False)\n",
        "    return input_"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLWYsZeL3yUX"
      },
      "source": [
        "path = 'yang91/'\n",
        "files_y = glob.glob(path + '*.*')\n",
        "trainfiles = files_y[:60]             #HERE TOTAL IMAGES ARE 91 , SO FROM 91 up to 85 used for Training\n",
        "valfiles = files_y[60:]               #HERE Above 85 used for Validation Set\n",
        "img_size = 32\n",
        "stride = 16\n",
        "X_train = []\n",
        "Y_train = []\n",
        "X_val = []\n",
        "Y_val = []"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MToRvvqZ5Yrw",
        "outputId": "b3048fef-3b9a-4c9c-bc7a-e02fe736dc58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Extract patch image for training\n",
        "for file_y in trainfiles:\n",
        "    tmp_y = scipy.misc.imread(file_y,flatten=True, mode='YCbCr').astype(np.float)\n",
        "    tmp_X = create_LR(tmp_y,2) #############################################################SCALE###########\n",
        "    h,w = tmp_y.shape\n",
        "    for x in range(0, h-img_size+1, stride):\n",
        "        for y in range(0, w-img_size+1, stride):\n",
        "            sub_input = tmp_X[x:x+img_size,y:y+img_size].reshape(img_size,img_size,1)\n",
        "            sub_label = tmp_y[x:x+img_size, y:y+img_size].reshape(img_size,img_size,1)\n",
        "            X_train.append(sub_input)\n",
        "            Y_train.append(sub_label)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning:     `imread` is deprecated!\n",
            "    `imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "    Use ``imageio.imread`` instead.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AlQ2eIa51M-",
        "outputId": "3ef88d24-4706-4a73-8eb6-a24fdf133860",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Extract patch image for validation\n",
        "for file_y in valfiles:\n",
        "    tmp_y = scipy.misc.imread(file_y,flatten=True, mode='YCbCr').astype(np.float)\n",
        "    tmp_X = create_LR(tmp_y,2)###########################################################SCALE################\n",
        "    h,w = tmp_y.shape\n",
        "    for x in range(0, h-img_size+1, stride):\n",
        "        for y in range(0, w-img_size+1, stride):\n",
        "            sub_input = tmp_X[x:x+img_size,  y:y+img_size].reshape(img_size,img_size,1) # [32 x 32]\n",
        "            sub_label = tmp_y[x:x+img_size, y:y+img_size].reshape(img_size,img_size,1) # [32 x 32]\n",
        "            X_val.append(sub_input)\n",
        "            Y_val.append(sub_label)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning:     `imread` is deprecated!\n",
            "    `imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "    Use ``imageio.imread`` instead.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0II1RFE856fP"
      },
      "source": [
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "X_val = np.array(X_val)\n",
        "Y_val = np.array(Y_val)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0o5JA-BK3UN"
      },
      "source": [
        "LEARN_RATE = 1.0e-4"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HvRcw0YKhIA"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam, SGD"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsVNKmUyKWoY"
      },
      "source": [
        "checkpoint = ModelCheckpoint('best_model_improved.h5',  # model filename\n",
        "                             monitor='val_loss', # quantity to monitor\n",
        "                             verbose=0, # verbosity - 0 or 1\n",
        "                             save_best_only= True, # The latest best model will not be overwritten\n",
        "                             mode='auto') # The decision to overwrite model is made \n",
        "                                          # automatically depending on the quantity to monitor"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNpY9WWtKuhT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbb20b5b-e055-4c64-a9bf-7f818676daab"
      },
      "source": [
        "model.compile(loss='mse', # Better loss function for neural networks\n",
        "              optimizer=Adam(lr=LEARN_RATE), # Adam optimizer with 1.0e-4 learning rate\n",
        "              metrics = ['accuracy']) # Metrics to be evaluated by the model"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5_DUkWsLG-9",
        "outputId": "779312df-747c-44df-e89f-129a174a5ecb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = model.fit(X_train, Y_train,\n",
        "                    batch_size = 128,\n",
        "                    epochs = 500, # number of iterations\n",
        "                    validation_data= (X_val, Y_val),\n",
        "                    callbacks=[checkpoint],\n",
        "                    verbose=1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 484.5235 - accuracy: 3.4246e-04 - val_loss: 603.1169 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 470.9720 - accuracy: 3.4602e-04 - val_loss: 588.6639 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 456.8326 - accuracy: 3.4909e-04 - val_loss: 573.5207 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 441.9596 - accuracy: 3.4992e-04 - val_loss: 557.4783 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 426.2077 - accuracy: 3.4998e-04 - val_loss: 540.4614 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 409.5449 - accuracy: 3.5122e-04 - val_loss: 522.2901 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 391.7373 - accuracy: 3.5320e-04 - val_loss: 502.7697 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 372.9727 - accuracy: 3.5409e-04 - val_loss: 482.6614 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 353.8170 - accuracy: 3.5436e-04 - val_loss: 461.9921 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 334.5894 - accuracy: 3.5532e-04 - val_loss: 441.5348 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 316.0423 - accuracy: 3.5587e-04 - val_loss: 422.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 298.8139 - accuracy: 3.5662e-04 - val_loss: 404.0488 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 283.5076 - accuracy: 3.5764e-04 - val_loss: 388.2522 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 270.4489 - accuracy: 3.5723e-04 - val_loss: 374.8217 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 259.6178 - accuracy: 3.5696e-04 - val_loss: 363.3943 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 250.6698 - accuracy: 3.5847e-04 - val_loss: 353.7616 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 243.1090 - accuracy: 3.5853e-04 - val_loss: 345.5931 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 236.5366 - accuracy: 3.5894e-04 - val_loss: 338.1653 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 230.6363 - accuracy: 3.5901e-04 - val_loss: 331.3444 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 225.1945 - accuracy: 3.5805e-04 - val_loss: 325.0675 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/500\n",
            "112/112 [==============================] - 3s 24ms/step - loss: 220.0312 - accuracy: 3.5805e-04 - val_loss: 319.1431 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/500\n",
            "112/112 [==============================] - 3s 23ms/step - loss: 215.0988 - accuracy: 3.5819e-04 - val_loss: 313.4006 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 210.4425 - accuracy: 3.5908e-04 - val_loss: 308.0339 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 205.9702 - accuracy: 3.6011e-04 - val_loss: 302.8692 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 201.7360 - accuracy: 3.5929e-04 - val_loss: 297.9457 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 197.6376 - accuracy: 3.5888e-04 - val_loss: 293.3321 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 193.7802 - accuracy: 3.5799e-04 - val_loss: 288.8256 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 190.0466 - accuracy: 3.5751e-04 - val_loss: 284.5145 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 186.4584 - accuracy: 3.5737e-04 - val_loss: 280.3849 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 183.0256 - accuracy: 3.5696e-04 - val_loss: 276.4616 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 179.7161 - accuracy: 3.5703e-04 - val_loss: 272.6140 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 176.5041 - accuracy: 3.5764e-04 - val_loss: 268.9687 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 173.4507 - accuracy: 3.5737e-04 - val_loss: 265.4339 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 170.4643 - accuracy: 3.5607e-04 - val_loss: 261.9928 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 167.6227 - accuracy: 3.5703e-04 - val_loss: 258.7863 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 164.8804 - accuracy: 3.5682e-04 - val_loss: 255.6545 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 162.2082 - accuracy: 3.5614e-04 - val_loss: 252.5070 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 159.6678 - accuracy: 3.5573e-04 - val_loss: 249.6479 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 157.1931 - accuracy: 3.5525e-04 - val_loss: 246.7289 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 154.8493 - accuracy: 3.5525e-04 - val_loss: 243.9966 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 152.5626 - accuracy: 3.5552e-04 - val_loss: 241.3902 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 150.4418 - accuracy: 3.5552e-04 - val_loss: 238.9034 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 148.3768 - accuracy: 3.5368e-04 - val_loss: 236.5548 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 146.4536 - accuracy: 3.5190e-04 - val_loss: 234.3611 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 144.6554 - accuracy: 3.5060e-04 - val_loss: 232.4041 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 142.9863 - accuracy: 3.5046e-04 - val_loss: 230.2233 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 141.4167 - accuracy: 3.4937e-04 - val_loss: 228.3758 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 139.9489 - accuracy: 3.4923e-04 - val_loss: 226.6170 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 138.5823 - accuracy: 3.4697e-04 - val_loss: 224.9093 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 137.2628 - accuracy: 3.4622e-04 - val_loss: 223.2900 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 136.0197 - accuracy: 3.4444e-04 - val_loss: 221.7467 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 134.8238 - accuracy: 3.4287e-04 - val_loss: 220.2002 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 133.6696 - accuracy: 3.4205e-04 - val_loss: 218.7044 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 132.5615 - accuracy: 3.4000e-04 - val_loss: 217.2426 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/500\n",
            "112/112 [==============================] - 2s 22ms/step - loss: 131.4811 - accuracy: 3.3911e-04 - val_loss: 215.8055 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 130.4238 - accuracy: 3.3754e-04 - val_loss: 214.4083 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 129.3971 - accuracy: 3.3754e-04 - val_loss: 213.0660 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 128.3896 - accuracy: 3.4055e-04 - val_loss: 211.6335 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 127.4071 - accuracy: 3.4007e-04 - val_loss: 210.2615 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 126.4297 - accuracy: 3.3706e-04 - val_loss: 208.9070 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 125.4696 - accuracy: 3.3220e-04 - val_loss: 207.5464 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 124.5256 - accuracy: 3.2885e-04 - val_loss: 206.2295 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 123.6234 - accuracy: 3.2283e-04 - val_loss: 204.9951 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 122.7473 - accuracy: 3.1756e-04 - val_loss: 203.6891 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 121.8973 - accuracy: 3.1332e-04 - val_loss: 202.4535 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 121.0705 - accuracy: 3.0402e-04 - val_loss: 201.2274 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 120.2583 - accuracy: 2.7947e-04 - val_loss: 200.0184 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 119.4731 - accuracy: 2.6613e-04 - val_loss: 198.8558 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 118.7066 - accuracy: 2.6107e-04 - val_loss: 197.7254 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 117.9723 - accuracy: 2.5464e-04 - val_loss: 196.6037 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 117.2464 - accuracy: 2.5259e-04 - val_loss: 195.4864 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 116.5380 - accuracy: 2.5006e-04 - val_loss: 194.3953 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 115.8336 - accuracy: 2.4876e-04 - val_loss: 193.3260 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 115.1535 - accuracy: 2.4848e-04 - val_loss: 192.2827 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 114.4871 - accuracy: 2.4814e-04 - val_loss: 191.2643 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 113.8418 - accuracy: 2.4787e-04 - val_loss: 190.2723 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 113.2056 - accuracy: 2.4794e-04 - val_loss: 189.2708 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 112.5768 - accuracy: 2.4801e-04 - val_loss: 188.2976 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 111.9630 - accuracy: 2.4807e-04 - val_loss: 187.3422 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 111.3651 - accuracy: 2.4780e-04 - val_loss: 186.4124 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 110.7677 - accuracy: 2.4896e-04 - val_loss: 185.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 110.2026 - accuracy: 2.4821e-04 - val_loss: 184.6029 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 109.6317 - accuracy: 2.4889e-04 - val_loss: 183.7392 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 109.0799 - accuracy: 2.4896e-04 - val_loss: 182.8325 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 108.5332 - accuracy: 2.5054e-04 - val_loss: 181.9862 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 107.9942 - accuracy: 2.5019e-04 - val_loss: 181.1583 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 107.4715 - accuracy: 2.5088e-04 - val_loss: 180.3191 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 106.9553 - accuracy: 2.5197e-04 - val_loss: 179.5142 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 106.4563 - accuracy: 2.5231e-04 - val_loss: 178.7337 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 105.9700 - accuracy: 2.5320e-04 - val_loss: 177.9753 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 105.5040 - accuracy: 2.5313e-04 - val_loss: 177.3643 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 105.0779 - accuracy: 2.5526e-04 - val_loss: 176.5618 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 104.6420 - accuracy: 2.5628e-04 - val_loss: 175.8935 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 104.2400 - accuracy: 2.5669e-04 - val_loss: 175.2624 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 103.8413 - accuracy: 2.5820e-04 - val_loss: 174.6620 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 103.4683 - accuracy: 2.5779e-04 - val_loss: 174.0676 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 103.1002 - accuracy: 2.5833e-04 - val_loss: 173.5566 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 102.7401 - accuracy: 2.5936e-04 - val_loss: 172.9413 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 102.4138 - accuracy: 2.5970e-04 - val_loss: 172.5214 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 102.0792 - accuracy: 2.6086e-04 - val_loss: 171.9485 - val_accuracy: 0.0000e+00\n",
            "Epoch 101/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 101.7683 - accuracy: 2.6127e-04 - val_loss: 171.4503 - val_accuracy: 0.0000e+00\n",
            "Epoch 102/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 101.4652 - accuracy: 2.6264e-04 - val_loss: 170.9858 - val_accuracy: 0.0000e+00\n",
            "Epoch 103/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 101.1705 - accuracy: 2.6333e-04 - val_loss: 170.5315 - val_accuracy: 0.0000e+00\n",
            "Epoch 104/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 100.8711 - accuracy: 2.6278e-04 - val_loss: 170.1181 - val_accuracy: 0.0000e+00\n",
            "Epoch 105/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 100.6075 - accuracy: 2.6298e-04 - val_loss: 169.6744 - val_accuracy: 0.0000e+00\n",
            "Epoch 106/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 100.3273 - accuracy: 2.6360e-04 - val_loss: 169.2603 - val_accuracy: 0.0000e+00\n",
            "Epoch 107/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 100.0657 - accuracy: 2.6428e-04 - val_loss: 168.8550 - val_accuracy: 0.0000e+00\n",
            "Epoch 108/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 99.8083 - accuracy: 2.6497e-04 - val_loss: 168.4750 - val_accuracy: 0.0000e+00\n",
            "Epoch 109/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 99.5538 - accuracy: 2.6640e-04 - val_loss: 168.0811 - val_accuracy: 0.0000e+00\n",
            "Epoch 110/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 99.3072 - accuracy: 2.6695e-04 - val_loss: 167.7056 - val_accuracy: 0.0000e+00\n",
            "Epoch 111/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 99.0689 - accuracy: 2.6777e-04 - val_loss: 167.3749 - val_accuracy: 0.0000e+00\n",
            "Epoch 112/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 98.8374 - accuracy: 2.6873e-04 - val_loss: 166.9815 - val_accuracy: 0.0000e+00\n",
            "Epoch 113/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 98.6077 - accuracy: 2.6934e-04 - val_loss: 166.6705 - val_accuracy: 0.0000e+00\n",
            "Epoch 114/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 98.3850 - accuracy: 2.7037e-04 - val_loss: 166.3120 - val_accuracy: 0.0000e+00\n",
            "Epoch 115/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 98.1718 - accuracy: 2.7379e-04 - val_loss: 166.0830 - val_accuracy: 0.0000e+00\n",
            "Epoch 116/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 97.9615 - accuracy: 2.7420e-04 - val_loss: 165.6696 - val_accuracy: 0.0000e+00\n",
            "Epoch 117/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 97.7597 - accuracy: 2.7447e-04 - val_loss: 165.3713 - val_accuracy: 0.0000e+00\n",
            "Epoch 118/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 97.5544 - accuracy: 2.7441e-04 - val_loss: 165.0834 - val_accuracy: 0.0000e+00\n",
            "Epoch 119/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 97.3714 - accuracy: 2.7721e-04 - val_loss: 164.7806 - val_accuracy: 0.0000e+00\n",
            "Epoch 120/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 97.1888 - accuracy: 2.7742e-04 - val_loss: 164.5307 - val_accuracy: 0.0000e+00\n",
            "Epoch 121/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 96.9941 - accuracy: 2.7612e-04 - val_loss: 164.2425 - val_accuracy: 0.0000e+00\n",
            "Epoch 122/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 96.8239 - accuracy: 2.7851e-04 - val_loss: 163.9875 - val_accuracy: 0.0000e+00\n",
            "Epoch 123/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 96.6519 - accuracy: 2.7824e-04 - val_loss: 163.7615 - val_accuracy: 0.0000e+00\n",
            "Epoch 124/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 96.4796 - accuracy: 2.7913e-04 - val_loss: 163.4878 - val_accuracy: 0.0000e+00\n",
            "Epoch 125/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 96.3222 - accuracy: 2.8008e-04 - val_loss: 163.2509 - val_accuracy: 0.0000e+00\n",
            "Epoch 126/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 96.1658 - accuracy: 2.8015e-04 - val_loss: 162.9851 - val_accuracy: 0.0000e+00\n",
            "Epoch 127/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 96.0018 - accuracy: 2.8186e-04 - val_loss: 162.7475 - val_accuracy: 0.0000e+00\n",
            "Epoch 128/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 95.8553 - accuracy: 2.8255e-04 - val_loss: 162.5186 - val_accuracy: 0.0000e+00\n",
            "Epoch 129/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 95.7057 - accuracy: 2.8343e-04 - val_loss: 162.2910 - val_accuracy: 0.0000e+00\n",
            "Epoch 130/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 95.5680 - accuracy: 2.8309e-04 - val_loss: 162.0828 - val_accuracy: 0.0000e+00\n",
            "Epoch 131/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 95.4264 - accuracy: 2.8426e-04 - val_loss: 161.8639 - val_accuracy: 0.0000e+00\n",
            "Epoch 132/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 95.2945 - accuracy: 2.8638e-04 - val_loss: 161.6675 - val_accuracy: 0.0000e+00\n",
            "Epoch 133/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 95.1556 - accuracy: 2.8467e-04 - val_loss: 161.4744 - val_accuracy: 0.0000e+00\n",
            "Epoch 134/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 95.0268 - accuracy: 2.8576e-04 - val_loss: 161.2660 - val_accuracy: 0.0000e+00\n",
            "Epoch 135/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 94.8962 - accuracy: 2.8603e-04 - val_loss: 161.0731 - val_accuracy: 0.0000e+00\n",
            "Epoch 136/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 94.7748 - accuracy: 2.8590e-04 - val_loss: 160.9176 - val_accuracy: 0.0000e+00\n",
            "Epoch 137/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 94.6567 - accuracy: 2.8542e-04 - val_loss: 160.7657 - val_accuracy: 0.0000e+00\n",
            "Epoch 138/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 94.5286 - accuracy: 2.8638e-04 - val_loss: 160.5534 - val_accuracy: 0.0000e+00\n",
            "Epoch 139/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 94.4253 - accuracy: 2.8603e-04 - val_loss: 160.3643 - val_accuracy: 0.0000e+00\n",
            "Epoch 140/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 94.3088 - accuracy: 2.8610e-04 - val_loss: 160.1833 - val_accuracy: 0.0000e+00\n",
            "Epoch 141/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 94.1974 - accuracy: 2.8754e-04 - val_loss: 159.9845 - val_accuracy: 0.0000e+00\n",
            "Epoch 142/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 94.1000 - accuracy: 2.8501e-04 - val_loss: 159.8182 - val_accuracy: 0.0000e+00\n",
            "Epoch 143/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 94.0059 - accuracy: 2.8514e-04 - val_loss: 159.6645 - val_accuracy: 0.0000e+00\n",
            "Epoch 144/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 93.9022 - accuracy: 2.8638e-04 - val_loss: 159.5533 - val_accuracy: 0.0000e+00\n",
            "Epoch 145/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 93.7993 - accuracy: 2.8487e-04 - val_loss: 159.3759 - val_accuracy: 0.0000e+00\n",
            "Epoch 146/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 93.7033 - accuracy: 2.8685e-04 - val_loss: 159.2253 - val_accuracy: 0.0000e+00\n",
            "Epoch 147/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 93.6087 - accuracy: 2.8624e-04 - val_loss: 159.0833 - val_accuracy: 0.0000e+00\n",
            "Epoch 148/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 93.5227 - accuracy: 2.8569e-04 - val_loss: 158.9659 - val_accuracy: 0.0000e+00\n",
            "Epoch 149/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 93.4295 - accuracy: 2.8583e-04 - val_loss: 158.7971 - val_accuracy: 0.0000e+00\n",
            "Epoch 150/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 93.3361 - accuracy: 2.8624e-04 - val_loss: 158.6747 - val_accuracy: 0.0000e+00\n",
            "Epoch 151/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 93.2474 - accuracy: 2.8535e-04 - val_loss: 158.5116 - val_accuracy: 0.0000e+00\n",
            "Epoch 152/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 93.1642 - accuracy: 2.8631e-04 - val_loss: 158.3841 - val_accuracy: 0.0000e+00\n",
            "Epoch 153/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 93.0780 - accuracy: 2.8542e-04 - val_loss: 158.2411 - val_accuracy: 0.0000e+00\n",
            "Epoch 154/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 92.9933 - accuracy: 2.8596e-04 - val_loss: 158.1192 - val_accuracy: 0.0000e+00\n",
            "Epoch 155/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 92.9125 - accuracy: 2.8494e-04 - val_loss: 158.0043 - val_accuracy: 0.0000e+00\n",
            "Epoch 156/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 92.8263 - accuracy: 2.8439e-04 - val_loss: 157.9055 - val_accuracy: 0.0000e+00\n",
            "Epoch 157/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 92.7540 - accuracy: 2.8439e-04 - val_loss: 157.7683 - val_accuracy: 0.0000e+00\n",
            "Epoch 158/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 92.6696 - accuracy: 2.8412e-04 - val_loss: 157.6370 - val_accuracy: 0.0000e+00\n",
            "Epoch 159/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 92.5914 - accuracy: 2.8364e-04 - val_loss: 157.5364 - val_accuracy: 0.0000e+00\n",
            "Epoch 160/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 92.5095 - accuracy: 2.8405e-04 - val_loss: 157.4063 - val_accuracy: 0.0000e+00\n",
            "Epoch 161/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 92.4388 - accuracy: 2.8405e-04 - val_loss: 157.2661 - val_accuracy: 0.0000e+00\n",
            "Epoch 162/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 92.3638 - accuracy: 2.8357e-04 - val_loss: 157.1577 - val_accuracy: 0.0000e+00\n",
            "Epoch 163/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 92.2904 - accuracy: 2.8426e-04 - val_loss: 157.0355 - val_accuracy: 0.0000e+00\n",
            "Epoch 164/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 92.2096 - accuracy: 2.8514e-04 - val_loss: 156.9350 - val_accuracy: 0.0000e+00\n",
            "Epoch 165/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 92.1497 - accuracy: 2.8323e-04 - val_loss: 156.8335 - val_accuracy: 0.0000e+00\n",
            "Epoch 166/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 92.0678 - accuracy: 2.8364e-04 - val_loss: 156.7099 - val_accuracy: 0.0000e+00\n",
            "Epoch 167/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 92.0008 - accuracy: 2.8371e-04 - val_loss: 156.6034 - val_accuracy: 0.0000e+00\n",
            "Epoch 168/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 91.9270 - accuracy: 2.8432e-04 - val_loss: 156.5092 - val_accuracy: 0.0000e+00\n",
            "Epoch 169/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 91.8595 - accuracy: 2.8460e-04 - val_loss: 156.4082 - val_accuracy: 0.0000e+00\n",
            "Epoch 170/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 91.7920 - accuracy: 2.8330e-04 - val_loss: 156.2951 - val_accuracy: 0.0000e+00\n",
            "Epoch 171/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 91.7180 - accuracy: 2.8426e-04 - val_loss: 156.2484 - val_accuracy: 0.0000e+00\n",
            "Epoch 172/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 91.6479 - accuracy: 2.8364e-04 - val_loss: 156.0995 - val_accuracy: 0.0000e+00\n",
            "Epoch 173/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 91.5839 - accuracy: 2.8371e-04 - val_loss: 155.9774 - val_accuracy: 0.0000e+00\n",
            "Epoch 174/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 91.5066 - accuracy: 2.8384e-04 - val_loss: 155.8811 - val_accuracy: 0.0000e+00\n",
            "Epoch 175/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 91.4450 - accuracy: 2.8494e-04 - val_loss: 155.7788 - val_accuracy: 0.0000e+00\n",
            "Epoch 176/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 91.3741 - accuracy: 2.8296e-04 - val_loss: 155.6793 - val_accuracy: 0.0000e+00\n",
            "Epoch 177/500\n",
            "112/112 [==============================] - 2s 22ms/step - loss: 91.2959 - accuracy: 2.8378e-04 - val_loss: 155.5710 - val_accuracy: 0.0000e+00\n",
            "Epoch 178/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 91.2270 - accuracy: 2.8467e-04 - val_loss: 155.4792 - val_accuracy: 0.0000e+00\n",
            "Epoch 179/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 91.1490 - accuracy: 2.8432e-04 - val_loss: 155.5065 - val_accuracy: 0.0000e+00\n",
            "Epoch 180/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 91.0737 - accuracy: 2.8426e-04 - val_loss: 155.2362 - val_accuracy: 0.0000e+00\n",
            "Epoch 181/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 91.0027 - accuracy: 2.8432e-04 - val_loss: 155.1258 - val_accuracy: 0.0000e+00\n",
            "Epoch 182/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 90.9172 - accuracy: 2.8446e-04 - val_loss: 155.0226 - val_accuracy: 0.0000e+00\n",
            "Epoch 183/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 90.8251 - accuracy: 2.8460e-04 - val_loss: 154.8958 - val_accuracy: 0.0000e+00\n",
            "Epoch 184/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 90.7415 - accuracy: 2.8439e-04 - val_loss: 154.7592 - val_accuracy: 0.0000e+00\n",
            "Epoch 185/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 90.6483 - accuracy: 2.8439e-04 - val_loss: 154.6367 - val_accuracy: 0.0000e+00\n",
            "Epoch 186/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 90.5651 - accuracy: 2.8439e-04 - val_loss: 154.5397 - val_accuracy: 0.0000e+00\n",
            "Epoch 187/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 90.4906 - accuracy: 2.8453e-04 - val_loss: 154.3889 - val_accuracy: 0.0000e+00\n",
            "Epoch 188/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 90.3889 - accuracy: 2.8419e-04 - val_loss: 154.2504 - val_accuracy: 0.0000e+00\n",
            "Epoch 189/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 90.3060 - accuracy: 2.8446e-04 - val_loss: 154.1397 - val_accuracy: 0.0000e+00\n",
            "Epoch 190/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 90.2256 - accuracy: 2.8432e-04 - val_loss: 154.0316 - val_accuracy: 0.0000e+00\n",
            "Epoch 191/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 90.1449 - accuracy: 2.8357e-04 - val_loss: 153.8616 - val_accuracy: 0.0000e+00\n",
            "Epoch 192/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 90.0730 - accuracy: 2.8378e-04 - val_loss: 153.7346 - val_accuracy: 0.0000e+00\n",
            "Epoch 193/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 89.9897 - accuracy: 2.8371e-04 - val_loss: 153.6414 - val_accuracy: 0.0000e+00\n",
            "Epoch 194/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 89.9264 - accuracy: 2.8419e-04 - val_loss: 153.5060 - val_accuracy: 0.0000e+00\n",
            "Epoch 195/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 89.8372 - accuracy: 2.8316e-04 - val_loss: 153.3957 - val_accuracy: 0.0000e+00\n",
            "Epoch 196/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 89.7704 - accuracy: 2.8227e-04 - val_loss: 153.3050 - val_accuracy: 0.0000e+00\n",
            "Epoch 197/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 89.6924 - accuracy: 2.8316e-04 - val_loss: 153.1532 - val_accuracy: 0.0000e+00\n",
            "Epoch 198/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 89.6175 - accuracy: 2.8302e-04 - val_loss: 153.0455 - val_accuracy: 0.0000e+00\n",
            "Epoch 199/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 89.5509 - accuracy: 2.8302e-04 - val_loss: 152.9273 - val_accuracy: 0.0000e+00\n",
            "Epoch 200/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 89.4726 - accuracy: 2.8275e-04 - val_loss: 152.8158 - val_accuracy: 0.0000e+00\n",
            "Epoch 201/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 89.4129 - accuracy: 2.8282e-04 - val_loss: 152.7031 - val_accuracy: 0.0000e+00\n",
            "Epoch 202/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 89.3344 - accuracy: 2.8337e-04 - val_loss: 152.6749 - val_accuracy: 0.0000e+00\n",
            "Epoch 203/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 89.2690 - accuracy: 2.8159e-04 - val_loss: 152.4937 - val_accuracy: 0.0000e+00\n",
            "Epoch 204/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 89.1976 - accuracy: 2.8138e-04 - val_loss: 152.4274 - val_accuracy: 0.0000e+00\n",
            "Epoch 205/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 89.1255 - accuracy: 2.8302e-04 - val_loss: 152.2783 - val_accuracy: 0.0000e+00\n",
            "Epoch 206/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 89.0637 - accuracy: 2.8179e-04 - val_loss: 152.2231 - val_accuracy: 0.0000e+00\n",
            "Epoch 207/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 88.9984 - accuracy: 2.8049e-04 - val_loss: 152.0895 - val_accuracy: 0.0000e+00\n",
            "Epoch 208/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 88.9319 - accuracy: 2.8125e-04 - val_loss: 151.9812 - val_accuracy: 0.0000e+00\n",
            "Epoch 209/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 88.8586 - accuracy: 2.8138e-04 - val_loss: 151.8869 - val_accuracy: 0.0000e+00\n",
            "Epoch 210/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 88.7949 - accuracy: 2.8138e-04 - val_loss: 151.7932 - val_accuracy: 0.0000e+00\n",
            "Epoch 211/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 88.7315 - accuracy: 2.8118e-04 - val_loss: 151.6906 - val_accuracy: 0.0000e+00\n",
            "Epoch 212/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 88.6648 - accuracy: 2.8097e-04 - val_loss: 151.6316 - val_accuracy: 0.0000e+00\n",
            "Epoch 213/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 88.5991 - accuracy: 2.8070e-04 - val_loss: 151.5180 - val_accuracy: 0.0000e+00\n",
            "Epoch 214/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 88.5439 - accuracy: 2.8186e-04 - val_loss: 151.3853 - val_accuracy: 0.0000e+00\n",
            "Epoch 215/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 88.4781 - accuracy: 2.8179e-04 - val_loss: 151.2967 - val_accuracy: 0.0000e+00\n",
            "Epoch 216/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 88.4097 - accuracy: 2.8131e-04 - val_loss: 151.2023 - val_accuracy: 0.0000e+00\n",
            "Epoch 217/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 88.3517 - accuracy: 2.8056e-04 - val_loss: 151.1053 - val_accuracy: 0.0000e+00\n",
            "Epoch 218/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 88.2856 - accuracy: 2.8227e-04 - val_loss: 151.0289 - val_accuracy: 0.0000e+00\n",
            "Epoch 219/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 88.2304 - accuracy: 2.8118e-04 - val_loss: 150.9247 - val_accuracy: 0.0000e+00\n",
            "Epoch 220/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 88.1712 - accuracy: 2.8227e-04 - val_loss: 150.8723 - val_accuracy: 0.0000e+00\n",
            "Epoch 221/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 88.1161 - accuracy: 2.8268e-04 - val_loss: 150.7328 - val_accuracy: 0.0000e+00\n",
            "Epoch 222/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 88.0508 - accuracy: 2.8152e-04 - val_loss: 150.6642 - val_accuracy: 0.0000e+00\n",
            "Epoch 223/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 87.9948 - accuracy: 2.8145e-04 - val_loss: 150.5614 - val_accuracy: 0.0000e+00\n",
            "Epoch 224/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 87.9374 - accuracy: 2.8118e-04 - val_loss: 150.5098 - val_accuracy: 0.0000e+00\n",
            "Epoch 225/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 87.8749 - accuracy: 2.8207e-04 - val_loss: 150.3910 - val_accuracy: 0.0000e+00\n",
            "Epoch 226/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 87.8266 - accuracy: 2.8193e-04 - val_loss: 150.3259 - val_accuracy: 0.0000e+00\n",
            "Epoch 227/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 87.7717 - accuracy: 2.8296e-04 - val_loss: 150.2322 - val_accuracy: 0.0000e+00\n",
            "Epoch 228/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 87.7200 - accuracy: 2.8289e-04 - val_loss: 150.1462 - val_accuracy: 0.0000e+00\n",
            "Epoch 229/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 87.6683 - accuracy: 2.8248e-04 - val_loss: 150.1071 - val_accuracy: 0.0000e+00\n",
            "Epoch 230/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 87.6046 - accuracy: 2.8261e-04 - val_loss: 149.9759 - val_accuracy: 0.0000e+00\n",
            "Epoch 231/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 87.5657 - accuracy: 2.8255e-04 - val_loss: 149.9385 - val_accuracy: 0.0000e+00\n",
            "Epoch 232/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 87.5091 - accuracy: 2.8179e-04 - val_loss: 149.8222 - val_accuracy: 0.0000e+00\n",
            "Epoch 233/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 87.4589 - accuracy: 2.8330e-04 - val_loss: 149.7432 - val_accuracy: 0.0000e+00\n",
            "Epoch 234/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 87.4114 - accuracy: 2.8213e-04 - val_loss: 149.6640 - val_accuracy: 0.0000e+00\n",
            "Epoch 235/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 87.3559 - accuracy: 2.8378e-04 - val_loss: 149.5887 - val_accuracy: 0.0000e+00\n",
            "Epoch 236/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 87.3091 - accuracy: 2.8220e-04 - val_loss: 149.5453 - val_accuracy: 0.0000e+00\n",
            "Epoch 237/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 87.2580 - accuracy: 2.8350e-04 - val_loss: 149.4514 - val_accuracy: 0.0000e+00\n",
            "Epoch 238/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 87.2090 - accuracy: 2.8378e-04 - val_loss: 149.3745 - val_accuracy: 0.0000e+00\n",
            "Epoch 239/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 87.1625 - accuracy: 2.8255e-04 - val_loss: 149.3133 - val_accuracy: 0.0000e+00\n",
            "Epoch 240/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 87.1203 - accuracy: 2.8357e-04 - val_loss: 149.2243 - val_accuracy: 0.0000e+00\n",
            "Epoch 241/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 87.0669 - accuracy: 2.8432e-04 - val_loss: 149.1608 - val_accuracy: 0.0000e+00\n",
            "Epoch 242/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 87.0239 - accuracy: 2.8453e-04 - val_loss: 149.1010 - val_accuracy: 0.0000e+00\n",
            "Epoch 243/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 86.9699 - accuracy: 2.8480e-04 - val_loss: 148.9986 - val_accuracy: 0.0000e+00\n",
            "Epoch 244/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 86.9250 - accuracy: 2.8583e-04 - val_loss: 148.9246 - val_accuracy: 0.0000e+00\n",
            "Epoch 245/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 86.8967 - accuracy: 2.8480e-04 - val_loss: 148.8666 - val_accuracy: 0.0000e+00\n",
            "Epoch 246/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 86.8421 - accuracy: 2.8521e-04 - val_loss: 148.8130 - val_accuracy: 0.0000e+00\n",
            "Epoch 247/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 86.8001 - accuracy: 2.8501e-04 - val_loss: 148.7372 - val_accuracy: 0.0000e+00\n",
            "Epoch 248/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 86.7616 - accuracy: 2.8460e-04 - val_loss: 148.6894 - val_accuracy: 0.0000e+00\n",
            "Epoch 249/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 86.7144 - accuracy: 2.8555e-04 - val_loss: 148.5950 - val_accuracy: 0.0000e+00\n",
            "Epoch 250/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 86.6689 - accuracy: 2.8487e-04 - val_loss: 148.5388 - val_accuracy: 0.0000e+00\n",
            "Epoch 251/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 86.6251 - accuracy: 2.8480e-04 - val_loss: 148.4788 - val_accuracy: 0.0000e+00\n",
            "Epoch 252/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 86.5862 - accuracy: 2.8528e-04 - val_loss: 148.4152 - val_accuracy: 0.0000e+00\n",
            "Epoch 253/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 86.5532 - accuracy: 2.8542e-04 - val_loss: 148.3916 - val_accuracy: 0.0000e+00\n",
            "Epoch 254/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 86.5186 - accuracy: 2.8501e-04 - val_loss: 148.3198 - val_accuracy: 0.0000e+00\n",
            "Epoch 255/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 86.4699 - accuracy: 2.8480e-04 - val_loss: 148.2684 - val_accuracy: 0.0000e+00\n",
            "Epoch 256/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 86.4309 - accuracy: 2.8384e-04 - val_loss: 148.1890 - val_accuracy: 0.0000e+00\n",
            "Epoch 257/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 86.4072 - accuracy: 2.8487e-04 - val_loss: 148.1255 - val_accuracy: 0.0000e+00\n",
            "Epoch 258/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 86.3520 - accuracy: 2.8638e-04 - val_loss: 148.0821 - val_accuracy: 0.0000e+00\n",
            "Epoch 259/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 86.3187 - accuracy: 2.8494e-04 - val_loss: 148.0128 - val_accuracy: 0.0000e+00\n",
            "Epoch 260/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 86.2819 - accuracy: 2.8398e-04 - val_loss: 147.9656 - val_accuracy: 0.0000e+00\n",
            "Epoch 261/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 86.2494 - accuracy: 2.8562e-04 - val_loss: 147.9029 - val_accuracy: 0.0000e+00\n",
            "Epoch 262/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 86.2131 - accuracy: 2.8494e-04 - val_loss: 147.8495 - val_accuracy: 0.0000e+00\n",
            "Epoch 263/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 86.1707 - accuracy: 2.8501e-04 - val_loss: 147.8039 - val_accuracy: 0.0000e+00\n",
            "Epoch 264/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 86.1385 - accuracy: 2.8706e-04 - val_loss: 147.7870 - val_accuracy: 0.0000e+00\n",
            "Epoch 265/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 86.1029 - accuracy: 2.8432e-04 - val_loss: 147.6868 - val_accuracy: 0.0000e+00\n",
            "Epoch 266/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 86.0742 - accuracy: 2.8692e-04 - val_loss: 147.6331 - val_accuracy: 0.0000e+00\n",
            "Epoch 267/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 86.0290 - accuracy: 2.8590e-04 - val_loss: 147.5757 - val_accuracy: 0.0000e+00\n",
            "Epoch 268/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.9926 - accuracy: 2.8617e-04 - val_loss: 147.5468 - val_accuracy: 0.0000e+00\n",
            "Epoch 269/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.9599 - accuracy: 2.8720e-04 - val_loss: 147.4783 - val_accuracy: 0.0000e+00\n",
            "Epoch 270/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.9304 - accuracy: 2.8754e-04 - val_loss: 147.4686 - val_accuracy: 0.0000e+00\n",
            "Epoch 271/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.9112 - accuracy: 2.8836e-04 - val_loss: 147.4033 - val_accuracy: 0.0000e+00\n",
            "Epoch 272/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.8609 - accuracy: 2.8829e-04 - val_loss: 147.3661 - val_accuracy: 0.0000e+00\n",
            "Epoch 273/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.8268 - accuracy: 2.8740e-04 - val_loss: 147.2801 - val_accuracy: 0.0000e+00\n",
            "Epoch 274/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 85.7917 - accuracy: 2.8843e-04 - val_loss: 147.3255 - val_accuracy: 0.0000e+00\n",
            "Epoch 275/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.7657 - accuracy: 2.8740e-04 - val_loss: 147.1793 - val_accuracy: 0.0000e+00\n",
            "Epoch 276/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.7393 - accuracy: 2.8980e-04 - val_loss: 147.1303 - val_accuracy: 0.0000e+00\n",
            "Epoch 277/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.7044 - accuracy: 2.8754e-04 - val_loss: 147.0924 - val_accuracy: 0.0000e+00\n",
            "Epoch 278/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.6674 - accuracy: 2.8897e-04 - val_loss: 147.0608 - val_accuracy: 0.0000e+00\n",
            "Epoch 279/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.6309 - accuracy: 2.9062e-04 - val_loss: 147.0147 - val_accuracy: 0.0000e+00\n",
            "Epoch 280/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.6107 - accuracy: 2.9137e-04 - val_loss: 146.9503 - val_accuracy: 0.0000e+00\n",
            "Epoch 281/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.5777 - accuracy: 2.9096e-04 - val_loss: 146.9438 - val_accuracy: 0.0000e+00\n",
            "Epoch 282/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.5490 - accuracy: 2.9233e-04 - val_loss: 146.8687 - val_accuracy: 0.0000e+00\n",
            "Epoch 283/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.5157 - accuracy: 2.9239e-04 - val_loss: 146.8204 - val_accuracy: 0.0000e+00\n",
            "Epoch 284/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.4832 - accuracy: 2.9301e-04 - val_loss: 146.7854 - val_accuracy: 0.0000e+00\n",
            "Epoch 285/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.4573 - accuracy: 2.9376e-04 - val_loss: 146.7260 - val_accuracy: 0.0000e+00\n",
            "Epoch 286/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.4222 - accuracy: 2.9431e-04 - val_loss: 146.6865 - val_accuracy: 0.0000e+00\n",
            "Epoch 287/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.3966 - accuracy: 2.9376e-04 - val_loss: 146.6769 - val_accuracy: 0.0000e+00\n",
            "Epoch 288/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.3665 - accuracy: 2.9397e-04 - val_loss: 146.6017 - val_accuracy: 0.0000e+00\n",
            "Epoch 289/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.3309 - accuracy: 2.9602e-04 - val_loss: 146.5972 - val_accuracy: 0.0000e+00\n",
            "Epoch 290/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.3110 - accuracy: 2.9431e-04 - val_loss: 146.5354 - val_accuracy: 0.0000e+00\n",
            "Epoch 291/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.2845 - accuracy: 2.9636e-04 - val_loss: 146.4817 - val_accuracy: 0.0000e+00\n",
            "Epoch 292/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.2485 - accuracy: 2.9711e-04 - val_loss: 146.4361 - val_accuracy: 0.0000e+00\n",
            "Epoch 293/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.2179 - accuracy: 2.9520e-04 - val_loss: 146.4337 - val_accuracy: 0.0000e+00\n",
            "Epoch 294/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.1953 - accuracy: 2.9930e-04 - val_loss: 146.4800 - val_accuracy: 0.0000e+00\n",
            "Epoch 295/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.1732 - accuracy: 3.0094e-04 - val_loss: 146.3140 - val_accuracy: 0.0000e+00\n",
            "Epoch 296/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.1331 - accuracy: 2.9964e-04 - val_loss: 146.3006 - val_accuracy: 0.0000e+00\n",
            "Epoch 297/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.1090 - accuracy: 3.0046e-04 - val_loss: 146.3177 - val_accuracy: 0.0000e+00\n",
            "Epoch 298/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.0802 - accuracy: 2.9910e-04 - val_loss: 146.2093 - val_accuracy: 0.0000e+00\n",
            "Epoch 299/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.0643 - accuracy: 3.0142e-04 - val_loss: 146.1771 - val_accuracy: 0.0000e+00\n",
            "Epoch 300/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.0391 - accuracy: 3.0320e-04 - val_loss: 146.2058 - val_accuracy: 0.0000e+00\n",
            "Epoch 301/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 85.0037 - accuracy: 3.0491e-04 - val_loss: 146.1025 - val_accuracy: 0.0000e+00\n",
            "Epoch 302/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.9710 - accuracy: 3.0026e-04 - val_loss: 146.0686 - val_accuracy: 0.0000e+00\n",
            "Epoch 303/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.9468 - accuracy: 3.0792e-04 - val_loss: 146.0281 - val_accuracy: 0.0000e+00\n",
            "Epoch 304/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.9249 - accuracy: 3.0901e-04 - val_loss: 146.0365 - val_accuracy: 0.0000e+00\n",
            "Epoch 305/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.9001 - accuracy: 3.0505e-04 - val_loss: 145.9420 - val_accuracy: 0.0000e+00\n",
            "Epoch 306/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.8749 - accuracy: 3.1859e-04 - val_loss: 145.9055 - val_accuracy: 0.0000e+00\n",
            "Epoch 307/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.8431 - accuracy: 3.0559e-04 - val_loss: 145.8738 - val_accuracy: 0.0000e+00\n",
            "Epoch 308/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.8293 - accuracy: 3.1729e-04 - val_loss: 145.8572 - val_accuracy: 0.0000e+00\n",
            "Epoch 309/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.8012 - accuracy: 3.1763e-04 - val_loss: 145.8382 - val_accuracy: 0.0000e+00\n",
            "Epoch 310/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.7731 - accuracy: 3.1880e-04 - val_loss: 145.7814 - val_accuracy: 0.0000e+00\n",
            "Epoch 311/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.7422 - accuracy: 3.1927e-04 - val_loss: 145.7566 - val_accuracy: 0.0000e+00\n",
            "Epoch 312/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.7173 - accuracy: 3.1955e-04 - val_loss: 145.7224 - val_accuracy: 0.0000e+00\n",
            "Epoch 313/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.6953 - accuracy: 3.2009e-04 - val_loss: 145.6899 - val_accuracy: 0.0000e+00\n",
            "Epoch 314/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.6676 - accuracy: 3.2051e-04 - val_loss: 145.6511 - val_accuracy: 0.0000e+00\n",
            "Epoch 315/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.6434 - accuracy: 3.2242e-04 - val_loss: 145.6057 - val_accuracy: 0.0000e+00\n",
            "Epoch 316/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.6170 - accuracy: 3.2222e-04 - val_loss: 145.5636 - val_accuracy: 0.0000e+00\n",
            "Epoch 317/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.5921 - accuracy: 3.2365e-04 - val_loss: 145.5295 - val_accuracy: 0.0000e+00\n",
            "Epoch 318/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.5653 - accuracy: 3.2222e-04 - val_loss: 145.5028 - val_accuracy: 0.0000e+00\n",
            "Epoch 319/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.5478 - accuracy: 3.2379e-04 - val_loss: 145.5089 - val_accuracy: 0.0000e+00\n",
            "Epoch 320/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.5226 - accuracy: 3.2434e-04 - val_loss: 145.4256 - val_accuracy: 0.0000e+00\n",
            "Epoch 321/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.5002 - accuracy: 3.2386e-04 - val_loss: 145.4001 - val_accuracy: 0.0000e+00\n",
            "Epoch 322/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.4773 - accuracy: 3.2392e-04 - val_loss: 145.3885 - val_accuracy: 0.0000e+00\n",
            "Epoch 323/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.4446 - accuracy: 3.2468e-04 - val_loss: 145.3587 - val_accuracy: 0.0000e+00\n",
            "Epoch 324/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.4215 - accuracy: 3.2495e-04 - val_loss: 145.3235 - val_accuracy: 0.0000e+00\n",
            "Epoch 325/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.4005 - accuracy: 3.2536e-04 - val_loss: 145.3127 - val_accuracy: 0.0000e+00\n",
            "Epoch 326/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.3748 - accuracy: 3.2488e-04 - val_loss: 145.2359 - val_accuracy: 0.0000e+00\n",
            "Epoch 327/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.3589 - accuracy: 3.2488e-04 - val_loss: 145.2358 - val_accuracy: 0.0000e+00\n",
            "Epoch 328/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.3329 - accuracy: 3.2577e-04 - val_loss: 145.1854 - val_accuracy: 0.0000e+00\n",
            "Epoch 329/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.3076 - accuracy: 3.2447e-04 - val_loss: 145.1493 - val_accuracy: 0.0000e+00\n",
            "Epoch 330/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.2837 - accuracy: 3.2570e-04 - val_loss: 145.1194 - val_accuracy: 0.0000e+00\n",
            "Epoch 331/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.2631 - accuracy: 3.2605e-04 - val_loss: 145.0921 - val_accuracy: 0.0000e+00\n",
            "Epoch 332/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.2318 - accuracy: 3.2509e-04 - val_loss: 145.0660 - val_accuracy: 0.0000e+00\n",
            "Epoch 333/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.2185 - accuracy: 3.2509e-04 - val_loss: 145.0479 - val_accuracy: 0.0000e+00\n",
            "Epoch 334/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.1918 - accuracy: 3.2557e-04 - val_loss: 145.0222 - val_accuracy: 0.0000e+00\n",
            "Epoch 335/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.1743 - accuracy: 3.2577e-04 - val_loss: 144.9871 - val_accuracy: 0.0000e+00\n",
            "Epoch 336/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.1611 - accuracy: 3.2598e-04 - val_loss: 144.9466 - val_accuracy: 0.0000e+00\n",
            "Epoch 337/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.1230 - accuracy: 3.2652e-04 - val_loss: 144.9187 - val_accuracy: 0.0000e+00\n",
            "Epoch 338/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.1034 - accuracy: 3.2632e-04 - val_loss: 144.9239 - val_accuracy: 0.0000e+00\n",
            "Epoch 339/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.0787 - accuracy: 3.2721e-04 - val_loss: 144.8634 - val_accuracy: 0.0000e+00\n",
            "Epoch 340/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.0657 - accuracy: 3.2673e-04 - val_loss: 144.8561 - val_accuracy: 0.0000e+00\n",
            "Epoch 341/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.0337 - accuracy: 3.2741e-04 - val_loss: 144.8191 - val_accuracy: 0.0000e+00\n",
            "Epoch 342/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 84.0175 - accuracy: 3.2748e-04 - val_loss: 144.7983 - val_accuracy: 0.0000e+00\n",
            "Epoch 343/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.9901 - accuracy: 3.2734e-04 - val_loss: 144.7598 - val_accuracy: 0.0000e+00\n",
            "Epoch 344/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.9689 - accuracy: 3.2817e-04 - val_loss: 144.7256 - val_accuracy: 0.0000e+00\n",
            "Epoch 345/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.9443 - accuracy: 3.2782e-04 - val_loss: 144.7159 - val_accuracy: 0.0000e+00\n",
            "Epoch 346/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.9294 - accuracy: 3.2892e-04 - val_loss: 144.6645 - val_accuracy: 0.0000e+00\n",
            "Epoch 347/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.9091 - accuracy: 3.2858e-04 - val_loss: 144.6472 - val_accuracy: 0.0000e+00\n",
            "Epoch 348/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.8820 - accuracy: 3.2871e-04 - val_loss: 144.6131 - val_accuracy: 0.0000e+00\n",
            "Epoch 349/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.8729 - accuracy: 3.2912e-04 - val_loss: 144.5775 - val_accuracy: 0.0000e+00\n",
            "Epoch 350/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.8470 - accuracy: 3.2912e-04 - val_loss: 144.5793 - val_accuracy: 0.0000e+00\n",
            "Epoch 351/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.8137 - accuracy: 3.2994e-04 - val_loss: 144.5244 - val_accuracy: 0.0000e+00\n",
            "Epoch 352/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.7989 - accuracy: 3.2885e-04 - val_loss: 144.5057 - val_accuracy: 0.0000e+00\n",
            "Epoch 353/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.7740 - accuracy: 3.2947e-04 - val_loss: 144.4892 - val_accuracy: 0.0000e+00\n",
            "Epoch 354/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.7586 - accuracy: 3.2933e-04 - val_loss: 144.4530 - val_accuracy: 0.0000e+00\n",
            "Epoch 355/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.7401 - accuracy: 3.2940e-04 - val_loss: 144.4552 - val_accuracy: 0.0000e+00\n",
            "Epoch 356/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.7172 - accuracy: 3.2953e-04 - val_loss: 144.4101 - val_accuracy: 0.0000e+00\n",
            "Epoch 357/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.6974 - accuracy: 3.2994e-04 - val_loss: 144.3828 - val_accuracy: 0.0000e+00\n",
            "Epoch 358/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.6693 - accuracy: 3.3049e-04 - val_loss: 144.3458 - val_accuracy: 0.0000e+00\n",
            "Epoch 359/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 83.6506 - accuracy: 3.3042e-04 - val_loss: 144.3488 - val_accuracy: 0.0000e+00\n",
            "Epoch 360/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.6354 - accuracy: 3.3070e-04 - val_loss: 144.3019 - val_accuracy: 0.0000e+00\n",
            "Epoch 361/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.6145 - accuracy: 3.3111e-04 - val_loss: 144.2956 - val_accuracy: 0.0000e+00\n",
            "Epoch 362/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.5907 - accuracy: 3.3165e-04 - val_loss: 144.2617 - val_accuracy: 0.0000e+00\n",
            "Epoch 363/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.5724 - accuracy: 3.3206e-04 - val_loss: 144.2245 - val_accuracy: 0.0000e+00\n",
            "Epoch 364/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.5482 - accuracy: 3.3200e-04 - val_loss: 144.2091 - val_accuracy: 0.0000e+00\n",
            "Epoch 365/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.5304 - accuracy: 3.3323e-04 - val_loss: 144.1897 - val_accuracy: 0.0000e+00\n",
            "Epoch 366/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 83.5151 - accuracy: 3.3275e-04 - val_loss: 144.1585 - val_accuracy: 0.0000e+00\n",
            "Epoch 367/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.4919 - accuracy: 3.3330e-04 - val_loss: 144.1495 - val_accuracy: 0.0000e+00\n",
            "Epoch 368/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.4737 - accuracy: 3.3323e-04 - val_loss: 144.1159 - val_accuracy: 0.0000e+00\n",
            "Epoch 369/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.4566 - accuracy: 3.3439e-04 - val_loss: 144.0849 - val_accuracy: 0.0000e+00\n",
            "Epoch 370/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.4430 - accuracy: 3.3425e-04 - val_loss: 144.0730 - val_accuracy: 0.0000e+00\n",
            "Epoch 371/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.4096 - accuracy: 3.3412e-04 - val_loss: 144.0439 - val_accuracy: 0.0000e+00\n",
            "Epoch 372/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.4005 - accuracy: 3.3466e-04 - val_loss: 144.0105 - val_accuracy: 0.0000e+00\n",
            "Epoch 373/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.3701 - accuracy: 3.3589e-04 - val_loss: 143.9899 - val_accuracy: 0.0000e+00\n",
            "Epoch 374/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.3548 - accuracy: 3.3651e-04 - val_loss: 143.9804 - val_accuracy: 0.0000e+00\n",
            "Epoch 375/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.3326 - accuracy: 3.3665e-04 - val_loss: 143.9383 - val_accuracy: 0.0000e+00\n",
            "Epoch 376/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.3204 - accuracy: 3.3726e-04 - val_loss: 143.9109 - val_accuracy: 0.0000e+00\n",
            "Epoch 377/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 83.2960 - accuracy: 3.3760e-04 - val_loss: 143.9211 - val_accuracy: 0.0000e+00\n",
            "Epoch 378/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 83.2833 - accuracy: 3.3795e-04 - val_loss: 143.8776 - val_accuracy: 0.0000e+00\n",
            "Epoch 379/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.2617 - accuracy: 3.3836e-04 - val_loss: 143.8384 - val_accuracy: 0.0000e+00\n",
            "Epoch 380/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.2669 - accuracy: 3.3897e-04 - val_loss: 143.8344 - val_accuracy: 0.0000e+00\n",
            "Epoch 381/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.2261 - accuracy: 3.3890e-04 - val_loss: 143.8086 - val_accuracy: 0.0000e+00\n",
            "Epoch 382/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.2037 - accuracy: 3.3938e-04 - val_loss: 143.7830 - val_accuracy: 0.0000e+00\n",
            "Epoch 383/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.1862 - accuracy: 3.3945e-04 - val_loss: 143.7570 - val_accuracy: 0.0000e+00\n",
            "Epoch 384/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.1682 - accuracy: 3.4000e-04 - val_loss: 143.7423 - val_accuracy: 0.0000e+00\n",
            "Epoch 385/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.1570 - accuracy: 3.4068e-04 - val_loss: 143.7199 - val_accuracy: 0.0000e+00\n",
            "Epoch 386/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.1415 - accuracy: 3.4096e-04 - val_loss: 143.7065 - val_accuracy: 0.0000e+00\n",
            "Epoch 387/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.1218 - accuracy: 3.4150e-04 - val_loss: 143.6776 - val_accuracy: 0.0000e+00\n",
            "Epoch 388/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.1022 - accuracy: 3.4212e-04 - val_loss: 143.6617 - val_accuracy: 0.0000e+00\n",
            "Epoch 389/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.0881 - accuracy: 3.4273e-04 - val_loss: 143.6363 - val_accuracy: 0.0000e+00\n",
            "Epoch 390/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.0687 - accuracy: 3.4273e-04 - val_loss: 143.6254 - val_accuracy: 0.0000e+00\n",
            "Epoch 391/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.0464 - accuracy: 3.4314e-04 - val_loss: 143.5951 - val_accuracy: 0.0000e+00\n",
            "Epoch 392/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.0411 - accuracy: 3.4355e-04 - val_loss: 143.5710 - val_accuracy: 0.0000e+00\n",
            "Epoch 393/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 83.0212 - accuracy: 3.4458e-04 - val_loss: 143.5648 - val_accuracy: 0.0000e+00\n",
            "Epoch 394/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.9978 - accuracy: 3.4520e-04 - val_loss: 143.5533 - val_accuracy: 0.0000e+00\n",
            "Epoch 395/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.9853 - accuracy: 3.4506e-04 - val_loss: 143.5022 - val_accuracy: 0.0000e+00\n",
            "Epoch 396/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.9711 - accuracy: 3.4602e-04 - val_loss: 143.5230 - val_accuracy: 0.0000e+00\n",
            "Epoch 397/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.9633 - accuracy: 3.4629e-04 - val_loss: 143.4923 - val_accuracy: 0.0000e+00\n",
            "Epoch 398/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.9349 - accuracy: 3.4602e-04 - val_loss: 143.4515 - val_accuracy: 0.0000e+00\n",
            "Epoch 399/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 82.9208 - accuracy: 3.4602e-04 - val_loss: 143.4811 - val_accuracy: 0.0000e+00\n",
            "Epoch 400/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.9080 - accuracy: 3.4629e-04 - val_loss: 143.4179 - val_accuracy: 0.0000e+00\n",
            "Epoch 401/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.8907 - accuracy: 3.4615e-04 - val_loss: 143.3914 - val_accuracy: 0.0000e+00\n",
            "Epoch 402/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.8708 - accuracy: 3.4670e-04 - val_loss: 143.3774 - val_accuracy: 0.0000e+00\n",
            "Epoch 403/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.8570 - accuracy: 3.4704e-04 - val_loss: 143.3665 - val_accuracy: 0.0000e+00\n",
            "Epoch 404/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.8384 - accuracy: 3.4697e-04 - val_loss: 143.3351 - val_accuracy: 0.0000e+00\n",
            "Epoch 405/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.8310 - accuracy: 3.4615e-04 - val_loss: 143.3121 - val_accuracy: 0.0000e+00\n",
            "Epoch 406/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.8168 - accuracy: 3.4711e-04 - val_loss: 143.3144 - val_accuracy: 0.0000e+00\n",
            "Epoch 407/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.7928 - accuracy: 3.4697e-04 - val_loss: 143.2996 - val_accuracy: 0.0000e+00\n",
            "Epoch 408/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.7841 - accuracy: 3.4711e-04 - val_loss: 143.2569 - val_accuracy: 0.0000e+00\n",
            "Epoch 409/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.7609 - accuracy: 3.4786e-04 - val_loss: 143.2520 - val_accuracy: 0.0000e+00\n",
            "Epoch 410/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.7469 - accuracy: 3.4759e-04 - val_loss: 143.2851 - val_accuracy: 0.0000e+00\n",
            "Epoch 411/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.7338 - accuracy: 3.4773e-04 - val_loss: 143.2065 - val_accuracy: 0.0000e+00\n",
            "Epoch 412/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.7240 - accuracy: 3.4793e-04 - val_loss: 143.1963 - val_accuracy: 0.0000e+00\n",
            "Epoch 413/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.6983 - accuracy: 3.4786e-04 - val_loss: 143.1853 - val_accuracy: 0.0000e+00\n",
            "Epoch 414/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.6854 - accuracy: 3.4800e-04 - val_loss: 143.1600 - val_accuracy: 0.0000e+00\n",
            "Epoch 415/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.6756 - accuracy: 3.4827e-04 - val_loss: 143.1227 - val_accuracy: 0.0000e+00\n",
            "Epoch 416/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.6588 - accuracy: 3.4834e-04 - val_loss: 143.1217 - val_accuracy: 0.0000e+00\n",
            "Epoch 417/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 82.6554 - accuracy: 3.4889e-04 - val_loss: 143.1558 - val_accuracy: 0.0000e+00\n",
            "Epoch 418/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 82.6265 - accuracy: 3.4862e-04 - val_loss: 143.0816 - val_accuracy: 0.0000e+00\n",
            "Epoch 419/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.6100 - accuracy: 3.4834e-04 - val_loss: 143.0510 - val_accuracy: 0.0000e+00\n",
            "Epoch 420/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.5984 - accuracy: 3.4848e-04 - val_loss: 143.0382 - val_accuracy: 0.0000e+00\n",
            "Epoch 421/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.5765 - accuracy: 3.4868e-04 - val_loss: 143.0743 - val_accuracy: 0.0000e+00\n",
            "Epoch 422/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.5681 - accuracy: 3.4889e-04 - val_loss: 143.0174 - val_accuracy: 0.0000e+00\n",
            "Epoch 423/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.5579 - accuracy: 3.4903e-04 - val_loss: 142.9865 - val_accuracy: 0.0000e+00\n",
            "Epoch 424/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.5370 - accuracy: 3.4964e-04 - val_loss: 142.9710 - val_accuracy: 0.0000e+00\n",
            "Epoch 425/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.5342 - accuracy: 3.4992e-04 - val_loss: 142.9534 - val_accuracy: 0.0000e+00\n",
            "Epoch 426/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.5105 - accuracy: 3.4985e-04 - val_loss: 142.9636 - val_accuracy: 0.0000e+00\n",
            "Epoch 427/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.4973 - accuracy: 3.4951e-04 - val_loss: 142.9485 - val_accuracy: 0.0000e+00\n",
            "Epoch 428/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.4798 - accuracy: 3.4951e-04 - val_loss: 142.9278 - val_accuracy: 0.0000e+00\n",
            "Epoch 429/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.4698 - accuracy: 3.4951e-04 - val_loss: 142.9018 - val_accuracy: 0.0000e+00\n",
            "Epoch 430/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.4539 - accuracy: 3.5005e-04 - val_loss: 142.8697 - val_accuracy: 0.0000e+00\n",
            "Epoch 431/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.4400 - accuracy: 3.5012e-04 - val_loss: 142.8675 - val_accuracy: 0.0000e+00\n",
            "Epoch 432/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 82.4249 - accuracy: 3.4978e-04 - val_loss: 142.9110 - val_accuracy: 0.0000e+00\n",
            "Epoch 433/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.4219 - accuracy: 3.4855e-04 - val_loss: 142.8356 - val_accuracy: 0.0000e+00\n",
            "Epoch 434/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.3904 - accuracy: 3.4937e-04 - val_loss: 142.8188 - val_accuracy: 0.0000e+00\n",
            "Epoch 435/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.3830 - accuracy: 3.5053e-04 - val_loss: 142.7939 - val_accuracy: 0.0000e+00\n",
            "Epoch 436/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.3884 - accuracy: 3.4903e-04 - val_loss: 142.8107 - val_accuracy: 0.0000e+00\n",
            "Epoch 437/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.3597 - accuracy: 3.4937e-04 - val_loss: 142.7417 - val_accuracy: 0.0000e+00\n",
            "Epoch 438/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.3396 - accuracy: 3.4868e-04 - val_loss: 142.7591 - val_accuracy: 0.0000e+00\n",
            "Epoch 439/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.3450 - accuracy: 3.4848e-04 - val_loss: 142.7116 - val_accuracy: 0.0000e+00\n",
            "Epoch 440/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.3222 - accuracy: 3.4780e-04 - val_loss: 142.6998 - val_accuracy: 0.0000e+00\n",
            "Epoch 441/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.3022 - accuracy: 3.4732e-04 - val_loss: 142.7511 - val_accuracy: 0.0000e+00\n",
            "Epoch 442/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.2947 - accuracy: 3.4704e-04 - val_loss: 142.6716 - val_accuracy: 0.0000e+00\n",
            "Epoch 443/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.2763 - accuracy: 3.4704e-04 - val_loss: 142.6542 - val_accuracy: 0.0000e+00\n",
            "Epoch 444/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.2676 - accuracy: 3.4609e-04 - val_loss: 142.6717 - val_accuracy: 0.0000e+00\n",
            "Epoch 445/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.2526 - accuracy: 3.4602e-04 - val_loss: 142.6344 - val_accuracy: 0.0000e+00\n",
            "Epoch 446/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.2401 - accuracy: 3.4609e-04 - val_loss: 142.6401 - val_accuracy: 0.0000e+00\n",
            "Epoch 447/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.2375 - accuracy: 3.4567e-04 - val_loss: 142.5821 - val_accuracy: 0.0000e+00\n",
            "Epoch 448/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.2250 - accuracy: 3.4526e-04 - val_loss: 142.6502 - val_accuracy: 0.0000e+00\n",
            "Epoch 449/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.2095 - accuracy: 3.4547e-04 - val_loss: 142.5672 - val_accuracy: 0.0000e+00\n",
            "Epoch 450/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.1861 - accuracy: 3.4465e-04 - val_loss: 142.5461 - val_accuracy: 0.0000e+00\n",
            "Epoch 451/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.1716 - accuracy: 3.4458e-04 - val_loss: 142.5325 - val_accuracy: 0.0000e+00\n",
            "Epoch 452/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.1747 - accuracy: 3.4444e-04 - val_loss: 142.5706 - val_accuracy: 0.0000e+00\n",
            "Epoch 453/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.1511 - accuracy: 3.4355e-04 - val_loss: 142.4911 - val_accuracy: 0.0000e+00\n",
            "Epoch 454/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.1437 - accuracy: 3.4479e-04 - val_loss: 142.5083 - val_accuracy: 0.0000e+00\n",
            "Epoch 455/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.1264 - accuracy: 3.4451e-04 - val_loss: 142.4732 - val_accuracy: 0.0000e+00\n",
            "Epoch 456/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.1131 - accuracy: 3.4458e-04 - val_loss: 142.4491 - val_accuracy: 0.0000e+00\n",
            "Epoch 457/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.1068 - accuracy: 3.4472e-04 - val_loss: 142.4726 - val_accuracy: 0.0000e+00\n",
            "Epoch 458/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.0912 - accuracy: 3.4492e-04 - val_loss: 142.4279 - val_accuracy: 0.0000e+00\n",
            "Epoch 459/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.0721 - accuracy: 3.4451e-04 - val_loss: 142.4002 - val_accuracy: 0.0000e+00\n",
            "Epoch 460/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.0698 - accuracy: 3.4485e-04 - val_loss: 142.4808 - val_accuracy: 0.0000e+00\n",
            "Epoch 461/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.0564 - accuracy: 3.4554e-04 - val_loss: 142.4581 - val_accuracy: 0.0000e+00\n",
            "Epoch 462/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.0396 - accuracy: 3.4602e-04 - val_loss: 142.3689 - val_accuracy: 0.0000e+00\n",
            "Epoch 463/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.0284 - accuracy: 3.4574e-04 - val_loss: 142.3491 - val_accuracy: 0.0000e+00\n",
            "Epoch 464/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 82.0156 - accuracy: 3.4602e-04 - val_loss: 142.3276 - val_accuracy: 0.0000e+00\n",
            "Epoch 465/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.9980 - accuracy: 3.4588e-04 - val_loss: 142.3194 - val_accuracy: 0.0000e+00\n",
            "Epoch 466/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.9873 - accuracy: 3.4622e-04 - val_loss: 142.3317 - val_accuracy: 0.0000e+00\n",
            "Epoch 467/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.9918 - accuracy: 3.4609e-04 - val_loss: 142.2769 - val_accuracy: 0.0000e+00\n",
            "Epoch 468/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.9675 - accuracy: 3.4615e-04 - val_loss: 142.3377 - val_accuracy: 0.0000e+00\n",
            "Epoch 469/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.9536 - accuracy: 3.4711e-04 - val_loss: 142.2798 - val_accuracy: 0.0000e+00\n",
            "Epoch 470/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.9442 - accuracy: 3.4718e-04 - val_loss: 142.2372 - val_accuracy: 0.0000e+00\n",
            "Epoch 471/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.9268 - accuracy: 3.4745e-04 - val_loss: 142.2166 - val_accuracy: 0.0000e+00\n",
            "Epoch 472/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.9185 - accuracy: 3.4725e-04 - val_loss: 142.2266 - val_accuracy: 0.0000e+00\n",
            "Epoch 473/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.9101 - accuracy: 3.4752e-04 - val_loss: 142.2282 - val_accuracy: 0.0000e+00\n",
            "Epoch 474/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.9017 - accuracy: 3.4786e-04 - val_loss: 142.1883 - val_accuracy: 0.0000e+00\n",
            "Epoch 475/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.8796 - accuracy: 3.4718e-04 - val_loss: 142.1682 - val_accuracy: 0.0000e+00\n",
            "Epoch 476/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.8699 - accuracy: 3.4759e-04 - val_loss: 142.1631 - val_accuracy: 0.0000e+00\n",
            "Epoch 477/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.8527 - accuracy: 3.4834e-04 - val_loss: 142.1352 - val_accuracy: 0.0000e+00\n",
            "Epoch 478/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.8411 - accuracy: 3.4738e-04 - val_loss: 142.1279 - val_accuracy: 0.0000e+00\n",
            "Epoch 479/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 81.8405 - accuracy: 3.4786e-04 - val_loss: 142.1311 - val_accuracy: 0.0000e+00\n",
            "Epoch 480/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.8194 - accuracy: 3.4800e-04 - val_loss: 142.0947 - val_accuracy: 0.0000e+00\n",
            "Epoch 481/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.8055 - accuracy: 3.4793e-04 - val_loss: 142.1044 - val_accuracy: 0.0000e+00\n",
            "Epoch 482/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.7938 - accuracy: 3.4786e-04 - val_loss: 142.0722 - val_accuracy: 0.0000e+00\n",
            "Epoch 483/500\n",
            "112/112 [==============================] - 2s 20ms/step - loss: 81.7861 - accuracy: 3.4855e-04 - val_loss: 142.0974 - val_accuracy: 0.0000e+00\n",
            "Epoch 484/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.7782 - accuracy: 3.4841e-04 - val_loss: 142.0485 - val_accuracy: 0.0000e+00\n",
            "Epoch 485/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.7606 - accuracy: 3.4827e-04 - val_loss: 142.0169 - val_accuracy: 0.0000e+00\n",
            "Epoch 486/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.7519 - accuracy: 3.4773e-04 - val_loss: 142.0124 - val_accuracy: 0.0000e+00\n",
            "Epoch 487/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.7367 - accuracy: 3.4807e-04 - val_loss: 141.9970 - val_accuracy: 0.0000e+00\n",
            "Epoch 488/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.7223 - accuracy: 3.4738e-04 - val_loss: 141.9781 - val_accuracy: 0.0000e+00\n",
            "Epoch 489/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.7174 - accuracy: 3.4800e-04 - val_loss: 142.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 490/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.7078 - accuracy: 3.4738e-04 - val_loss: 141.9920 - val_accuracy: 0.0000e+00\n",
            "Epoch 491/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.6965 - accuracy: 3.4793e-04 - val_loss: 141.9633 - val_accuracy: 0.0000e+00\n",
            "Epoch 492/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.6763 - accuracy: 3.4786e-04 - val_loss: 141.9173 - val_accuracy: 0.0000e+00\n",
            "Epoch 493/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.6737 - accuracy: 3.4766e-04 - val_loss: 141.9168 - val_accuracy: 0.0000e+00\n",
            "Epoch 494/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.6655 - accuracy: 3.4766e-04 - val_loss: 141.9142 - val_accuracy: 0.0000e+00\n",
            "Epoch 495/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.6433 - accuracy: 3.4752e-04 - val_loss: 141.9312 - val_accuracy: 0.0000e+00\n",
            "Epoch 496/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.6312 - accuracy: 3.4793e-04 - val_loss: 141.8936 - val_accuracy: 0.0000e+00\n",
            "Epoch 497/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.6175 - accuracy: 3.4800e-04 - val_loss: 141.8551 - val_accuracy: 0.0000e+00\n",
            "Epoch 498/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.6066 - accuracy: 3.4766e-04 - val_loss: 141.8509 - val_accuracy: 0.0000e+00\n",
            "Epoch 499/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.5962 - accuracy: 3.4780e-04 - val_loss: 141.8352 - val_accuracy: 0.0000e+00\n",
            "Epoch 500/500\n",
            "112/112 [==============================] - 2s 21ms/step - loss: 81.5854 - accuracy: 3.4766e-04 - val_loss: 141.8031 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrC8zWHsip-D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "7cbdcbf5-6384-413b-ec40-b5832c7a97c2"
      },
      "source": [
        "# Loss Curves\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(history.history['loss'],'r',linewidth=3.0)\n",
        "plt.plot(history.history['val_loss'],'b',linewidth=3.0)\n",
        "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.title('Loss Curves',fontsize=16)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Loss Curves')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YrW41ohi7mT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "6d1796ee-016c-49cf-9d8c-aaf53309e4a8"
      },
      "source": [
        "# Accuracy Curves\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(history.history['accuracy'],'r',linewidth=3.0)\n",
        "plt.plot(history.history['val_accuracy'],'b',linewidth=3.0)\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Accuracy',fontsize=16)\n",
        "plt.title('Accuracy Curves',fontsize=16)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-41fac66cb77c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Accuracy Curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Training Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Validation Accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIczDCs9Loa6"
      },
      "source": [
        "scores = model.evaluate(X_val, Y_val, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d06oTmPLok6"
      },
      "source": [
        "model.save('wscale2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1jtIWr8-cgO"
      },
      "source": [
        "img_o = scipy.misc.imread('baby_x2_GT.png',flatten=True,mode='YCbCr').astype(np.float)\n",
        "img = create_LR(img_o,2) #################################################################SCALE#################\n",
        "img_size = 32\n",
        "stride = 16\n",
        "h,w = img.shape\n",
        "piece_wise = []\n",
        "for x in range(0, h-img_size+1, stride):\n",
        "    for y in range (0, w-img_size+1, stride):\n",
        "        sub_input = img[x:x+img_size, y:y+img_size].reshape(img_size,img_size,1)\n",
        "        piece_wise.append(sub_input)\n",
        "input_ = np.asarray(piece_wise)\n",
        "srcnn = load_model('wscale2.h5')\n",
        "hat = srcnn.predict(input_)\n",
        "img_re = np.zeros(img.shape)\n",
        "i = 0\n",
        "for x in range(0, h-img_size+1, stride):\n",
        "    for y in range (0, w-img_size+1, stride):\n",
        "        img_re[x:x+img_size, y:y+img_size] = hat[i].reshape(img_size,img_size)\n",
        "        i += 1\n",
        "cv2.imwrite('restored1.bmp', img_re)\n",
        "cv2.imwrite('HR1.bmp', img_o)\n",
        "img_save = (img*255).astype(np.uint8)\n",
        "cv2.imwrite('blurred1.bmp',img_save)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J25TAo0R-dPI"
      },
      "source": [
        "#CALCULATE PSNR\n",
        "original = cv2.imread(\"HR1.bmp\")\n",
        "LR       = cv2.imread(\"blurred1.bmp\")\n",
        "contrast = cv2.imread(\"restored1.bmp\",1)\n",
        "def psnr(img1, img2):\n",
        "    mse = np.mean((img1-img2)**2)\n",
        "    if mse ==0:\n",
        "        return 100\n",
        "    PIXEL_MAX = 255.0\n",
        "    return 20* math.log10(PIXEL_MAX / math.sqrt(mse))\n",
        "d = psnr(original,contrast)\n",
        "print(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW3k7ocn-hnE"
      },
      "source": [
        "fig = plt.figure(figsize = (14,14), dpi = 100)\n",
        "ax = plt.subplot(\"131\")\n",
        "ax.imshow(original)\n",
        "ax.set_title(\"GT\")\n",
        "plt.grid(0)\n",
        "\n",
        "ax = plt.subplot(\"132\")\n",
        "ax.imshow(LR)\n",
        "ax.set_title(\"blurred_Image\")\n",
        "plt.grid(0)\n",
        "\n",
        "ax = plt.subplot(\"133\")\n",
        "ax.imshow(contrast)\n",
        "ax.set_title(\"HR_RECONSTRUCTED\")\n",
        "plt.grid(0)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPrLSYz_AZ8e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}