{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_PSNR_SSIM_MSE_IN_ONE.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "lU_4G2VErfyi",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "ee9827a3-252a-4191-eed8-d8c4729e4f02"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d4fe46c4-043d-4418-8d88-4388fe486025\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-d4fe46c4-043d-4418-8d88-4388fe486025\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving ML-Image-Super-Resolution-master.zip to ML-Image-Super-Resolution-master.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D0XL_KOo_0SJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://github.com/Pulkitdzrt/ML-Image-Super-Resolution/blob/master/Image%20Super%20Resolution%20with%20the%20SRCNN%20(Jupyter%20Notebook).ipynb"
      ]
    },
    {
      "metadata": {
        "id": "rmjrm2Ozx85P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d06231b9-6bf0-4944-decf-05f1c34bb4be"
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import keras\n",
        "import cv2\n",
        "import numpy\n",
        "import matplotlib\n",
        "import skimage"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "xAAEEMiQ7_UR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.optimizers import Adam\n",
        "from skimage.measure import compare_ssim as ssim\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n75L6dFH8Mxk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z7VJIVEr8Rpi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "2. Image Quality Metrics\n",
        "To start, lets define a couple of functions that we can use to calculate the PSNR, MSE, and SSIM. The structural similiarity (SSIM) index was imported directly from the scikit-image library; however, we will have to define our own functions for the PSNR and MSE. Furthermore, we will wrap all three of these metrics into a single function that we can call later.\n",
        "\n",
        "The PSNR block computes the peak signal-to-noise ratio, in decibels, between two images. This ratio is often used as a quality measurement between the original and a compressed image. The higher the PSNR, the better the quality of the compressed, or reconstructed image.\n",
        "\n",
        "The MSE is the cumulative squared error between the compressed and the original image, whereas PSNR is a measure of the peak error."
      ]
    },
    {
      "metadata": {
        "id": "X7Djqvnt8GCT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define a function for peak signal-to-noise ratio (PSNR)\n",
        "def psnr(target, ref):\n",
        "         \n",
        "    # assume RGB image\n",
        "    target_data = target.astype(float)\n",
        "    ref_data = ref.astype(float)\n",
        "\n",
        "    diff = ref_data - target_data\n",
        "    diff = diff.flatten('C')\n",
        "\n",
        "    rmse = math.sqrt(np.mean(diff ** 2.))\n",
        "\n",
        "    return 20 * math.log10(255. / rmse)\n",
        "\n",
        "# define function for mean squared error (MSE)\n",
        "def mse(target, ref):\n",
        "    # the MSE between the two images is the sum of the squared difference between the two images\n",
        "    err = np.sum((target.astype('float') - ref.astype('float')) ** 2)\n",
        "    err /= float(target.shape[0] * target.shape[1])\n",
        "    \n",
        "    return err\n",
        "\n",
        "# define function that combines all three image quality metrics\n",
        "def compare_images(target, ref):\n",
        "    scores = []\n",
        "    scores.append(psnr(target, ref))\n",
        "    scores.append(mse(target, ref))\n",
        "    scores.append(ssim(target, ref, multichannel =True))\n",
        "    \n",
        "    return scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PBZXcCLP8L8D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HHKYy-wv8aMY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "3. Preparing Images\n",
        "For this project, we will be using the same images that were used in the original SRCNN paper. We can download these images from http://mmlab.ie.cuhk.edu.hk/projects/SRCNN.html. The .zip file identified as the MATLAB code contains the images we want. Copy both the Set5 and Set14 datasets into a new folder called 'source'.\n",
        "\n",
        "Now that we have some images, we want to produce low resolution versions of these same images. We can accomplish this by resizing the images, both downwards and upwards, using OpeCV. There are several interpolation methods that can be used to resize images; however, we will be using bilinear interpolation.\n",
        "\n",
        "Once we produce these low resolution images, we can save them in a new folder."
      ]
    },
    {
      "metadata": {
        "id": "kG2qpD3V8bC2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# prepare degraded images by introducing quality distortions via resizing\n",
        "\n",
        "def prepare_images(path, factor):\n",
        "    \n",
        "    # loop through the files in the directory\n",
        "    for file in os.listdir(path):\n",
        "        \n",
        "        # open the file\n",
        "        img = cv2.imread(path + '/' + file)\n",
        "        \n",
        "        # find old and new image dimensions\n",
        "        h, w, _ = img.shape\n",
        "        new_height = h / factor\n",
        "        new_width = w / factor\n",
        "        \n",
        "        # resize the image - down\n",
        "        img = cv2.resize(img, (int(new_width), int(new_height)), interpolation = cv2.INTER_LINEAR)\n",
        "        \n",
        "        # resize the image - up\n",
        "        img = cv2.resize(img, (w, h), interpolation = cv2.INTER_LINEAR)\n",
        "        \n",
        "        # save the image\n",
        "        print('Saving {}'.format(file))\n",
        "        cv2.imwrite('images/{}'.format(file), img)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f8Weu30a8g_m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "7b868fdf-03e5-4c45-ee04-cf94a126bf76"
      },
      "cell_type": "code",
      "source": [
        "prepare_images('ML-Image-Super-Resolution-master/source/', 2)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving comic.bmp\n",
            "Saving woman_GT.bmp\n",
            "Saving zebra.bmp\n",
            "Saving bridge.bmp\n",
            "Saving flowers.bmp\n",
            "Saving man.bmp\n",
            "Saving pepper.bmp\n",
            "Saving lenna.bmp\n",
            "Saving face.bmp\n",
            "Saving baby_GT.bmp\n",
            "Saving butterfly_GT.bmp\n",
            "Saving foreman.bmp\n",
            "Saving ppt3.bmp\n",
            "Saving coastguard.bmp\n",
            "Saving monarch.bmp\n",
            "Saving baboon.bmp\n",
            "Saving bird_GT.bmp\n",
            "Saving head_GT.bmp\n",
            "Saving barbara.bmp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sCyu0vf_8m6n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e909a8d1-a369-4d35-aa7d-e3d4e71c6322"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.jpg\t\t\t\t      Output1.jpg\n",
            "ML-Image-Super-Resolution-master      Output2.jpg\n",
            "ML-Image-Super-Resolution-master.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DOUAdK57ANUC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "3. Testing Low Resolution Images\n",
        "To ensure that our image quality metrics are being calculated correctly and that the images were effectively degraded, lets calculate the PSNR, MSE, and SSIM between our reference images and the degraded images that we just prepared."
      ]
    },
    {
      "metadata": {
        "id": "PS81XZQj_719",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1632
        },
        "outputId": "c90d63db-ab41-41e2-f1da-5c512897c4be"
      },
      "cell_type": "code",
      "source": [
        "# test the generated images using the image quality metrics\n",
        "\n",
        "for file in os.listdir('ML-Image-Super-Resolution-master/images/'):\n",
        "    \n",
        "    # open target and reference images\n",
        "    target = cv2.imread('ML-Image-Super-Resolution-master/images/{}'.format(file))\n",
        "    ref = cv2.imread('ML-Image-Super-Resolution-master/source/{}'.format(file))\n",
        "    \n",
        "    # calculate score\n",
        "    scores = compare_images(target, ref)\n",
        "\n",
        "    # print all three scores with new line characters (\\n) \n",
        "    print('{}\\nPSNR: {}\\nMSE: {}\\nSSIM: {}\\n'.format(file, scores[0], scores[1], scores[2]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "comic.bmp\n",
            "PSNR: 23.799861502225532\n",
            "MSE: 813.2338836565096\n",
            "SSIM: 0.8347335416398209\n",
            "\n",
            "woman_GT.bmp\n",
            "PSNR: 29.326236280817465\n",
            "MSE: 227.812729498164\n",
            "SSIM: 0.9335397280466592\n",
            "\n",
            "zebra.bmp\n",
            "PSNR: 27.909840639329513\n",
            "MSE: 315.6585459528818\n",
            "SSIM: 0.8911656209329116\n",
            "\n",
            "bridge.bmp\n",
            "PSNR: 25.850528790115554\n",
            "MSE: 507.1643714904785\n",
            "SSIM: 0.7804245912255268\n",
            "\n",
            "flowers.bmp\n",
            "PSNR: 27.454504805386144\n",
            "MSE: 350.55093922651935\n",
            "SSIM: 0.8697286286974628\n",
            "\n",
            "man.bmp\n",
            "PSNR: 27.22646369798821\n",
            "MSE: 369.4496383666992\n",
            "SSIM: 0.8214950645456561\n",
            "\n",
            "pepper.bmp\n",
            "PSNR: 29.88947161686106\n",
            "MSE: 200.1033935546875\n",
            "SSIM: 0.8357937568464359\n",
            "\n",
            "lenna.bmp\n",
            "PSNR: 31.47349297867539\n",
            "MSE: 138.94800567626953\n",
            "SSIM: 0.8460989200521499\n",
            "\n",
            "face.bmp\n",
            "PSNR: 30.99220650287191\n",
            "MSE: 155.23189718546524\n",
            "SSIM: 0.8008439492289884\n",
            "\n",
            "baby_GT.bmp\n",
            "PSNR: 34.371806409661986\n",
            "MSE: 71.28874588012695\n",
            "SSIM: 0.9356987872724932\n",
            "\n",
            "butterfly_GT.bmp\n",
            "PSNR: 24.782076560337416\n",
            "MSE: 648.6254119873047\n",
            "SSIM: 0.8791344763843051\n",
            "\n",
            "foreman.bmp\n",
            "PSNR: 30.14456532664372\n",
            "MSE: 188.6883483270202\n",
            "SSIM: 0.933268417388899\n",
            "\n",
            "ppt3.bmp\n",
            "PSNR: 24.84926168950471\n",
            "MSE: 638.6684263912582\n",
            "SSIM: 0.9284023942315316\n",
            "\n",
            "coastguard.bmp\n",
            "PSNR: 27.161600663887082\n",
            "MSE: 375.00887784090907\n",
            "SSIM: 0.756950063354931\n",
            "\n",
            "monarch.bmp\n",
            "PSNR: 30.196242365288896\n",
            "MSE: 186.45643615722656\n",
            "SSIM: 0.9439574293434104\n",
            "\n",
            "baboon.bmp\n",
            "PSNR: 22.157084083442548\n",
            "MSE: 1187.1161333333334\n",
            "SSIM: 0.629277587900277\n",
            "\n",
            "bird_GT.bmp\n",
            "PSNR: 32.896644728720005\n",
            "MSE: 100.12375819830247\n",
            "SSIM: 0.9533644866026473\n",
            "\n",
            "head_GT.bmp\n",
            "PSNR: 31.020502848237534\n",
            "MSE: 154.2237755102041\n",
            "SSIM: 0.8011121330733371\n",
            "\n",
            "barbara.bmp\n",
            "PSNR: 25.906629837568126\n",
            "MSE: 500.65508535879627\n",
            "SSIM: 0.8098632646406401\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j3KMQ9mjAU11",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qx1HynhlAkGZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "4. Building the SRCNN Model\n",
        "Now that we have our low resolution images and all three image quality metrics functioning properly, we can start building the SRCNN. In Keras, it's as simple as adding layers one after the other. The achitecture and hyper parameters of the SRCNN network can be obtained from the publication referenced above."
      ]
    },
    {
      "metadata": {
        "id": "jtH0QXYpAk2B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define the SRCNN model\n",
        "def model():\n",
        "    \n",
        "    # define model type\n",
        "    SRCNN = Sequential()\n",
        "    \n",
        "    # add model layers\n",
        "    SRCNN.add(Conv2D(filters=128, kernel_size = (9, 9), kernel_initializer='glorot_uniform',\n",
        "                     activation='relu', padding='valid', use_bias=True, input_shape=(None, None, 1)))\n",
        "    SRCNN.add(Conv2D(filters=64, kernel_size = (3, 3), kernel_initializer='glorot_uniform',\n",
        "                     activation='relu', padding='same', use_bias=True))\n",
        "    SRCNN.add(Conv2D(filters=1, kernel_size = (5, 5), kernel_initializer='glorot_uniform',\n",
        "                     activation='linear', padding='valid', use_bias=True))\n",
        "    \n",
        "    # define optimizer\n",
        "    adam = Adam(lr=0.0003)\n",
        "    \n",
        "    # compile model\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    \n",
        "    return SRCNN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2FaAg-jNAr6Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kZiJ-g3bAxEn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "5. Deploying the SRCNN\n",
        "Now that we have defined our model, we can use it for single-image super-resolution. However, before we do this, we will need to define a couple of image processing functions. Furthermore, it will be necessary to preprocess the images extensively before using them as inputs to the network. This processing will include cropping and color space conversions.\n",
        "\n",
        "Additionally, to save us the time it takes to train a deep neural network, we will be loading pre-trained weights for the SRCNN. These weights can be found at the following GitHub page: https://github.com/MarkPrecursor/SRCNN-keras\n",
        "\n",
        "Once we have tested our network, we can perform single-image super-resolution on all of our input images. Furthermore, after processing, we can calculate the PSNR, MSE, and SSIM on the images that we produce. We can save these images directly or create subplots to conveniently display the original, low resolution, and high resolution images side by side."
      ]
    },
    {
      "metadata": {
        "id": "mFP22QfUAx4Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define necessary image processing functions\n",
        "\n",
        "def modcrop(img, scale):\n",
        "    tmpsz = img.shape\n",
        "    sz = tmpsz[0:2]\n",
        "    sz = sz - np.mod(sz, scale)\n",
        "    img = img[0:sz[0], 1:sz[1]]\n",
        "    return img\n",
        "\n",
        "\n",
        "def shave(image, border):\n",
        "    img = image[border: -border, border: -border]\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1QsqsRHsA1er",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define main prediction function\n",
        "\n",
        "def predict(image_path):\n",
        "    \n",
        "    # load the srcnn model with weights\n",
        "    srcnn = model()\n",
        "    srcnn.load_weights('ML-Image-Super-Resolution-master/3051crop_weight_200.h5')\n",
        "    \n",
        "    # load the degraded and reference images\n",
        "    path, file = os.path.split(image_path)\n",
        "    degraded = cv2.imread(image_path)\n",
        "    ref = cv2.imread('source/{}'.format(file))\n",
        "    \n",
        "    # preprocess the image with modcrop\n",
        "    ref = modcrop(ref, 3)\n",
        "    degraded = modcrop(degraded, 3)\n",
        "    \n",
        "    # convert the image to YCrCb - (srcnn trained on Y channel)\n",
        "    temp = cv2.cvtColor(degraded, cv2.COLOR_BGR2YCrCb)\n",
        "    \n",
        "    # create image slice and normalize\n",
        "    #print 'Shape: ', image_data.shape\n",
        "    #Shape:  (512, 512, 3)\n",
        "    #image_slice_red =  scaled_image_data[:,:,0]\n",
        "    #image_slice_green =  scaled_image_data[:,:,1]\n",
        "    #image_slice_blue =  scaled_image_data[:,:,2]\n",
        "    \n",
        "    Y = numpy.zeros((1, temp.shape[0], temp.shape[1], 1), dtype=float)\n",
        "    Y[0, :, :, 0] = temp[:, :, 0].astype(float) / 255\n",
        "    \n",
        "    # perform super-resolution with srcnn\n",
        "    pre = srcnn.predict(Y, batch_size=1)\n",
        "    \n",
        "    # post-process output\n",
        "    pre *= 255\n",
        "    pre[pre[:] > 255] = 255\n",
        "    pre[pre[:] < 0] = 0\n",
        "    pre = pre.astype(np.uint8)\n",
        "    \n",
        "    # copy Y channel back to image and convert to BGR\n",
        "    temp = shave(temp, 6)\n",
        "    temp[:, :, 0] = pre[0, :, :, 0]\n",
        "    output = cv2.cvtColor(temp, cv2.COLOR_YCrCb2BGR)\n",
        "    \n",
        "    # remove border from reference and degraged image\n",
        "    ref = shave(ref.astype(np.uint8), 6)\n",
        "    degraded = shave(degraded.astype(np.uint8), 6)\n",
        "    \n",
        "    # image quality calculations\n",
        "    scores = []\n",
        "    scores.append(compare_images(degraded, ref))\n",
        "    scores.append(compare_images(output, ref))\n",
        "    \n",
        "    # return images and scores\n",
        "    return ref, degraded, output, scores\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BL4yz7_dA-7f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "outputId": "e49a9e18-7ebc-492c-b67d-f22967a0004b"
      },
      "cell_type": "code",
      "source": [
        "ref, degraded, output, scores = predict('ML-Image-Super-Resolution-master/images/flowers.bmp')\n",
        "\n",
        "# print all scores for all images\n",
        "print('Degraded Image: \\nPSNR: {}\\nMSE: {}\\nSSIM: {}\\n'.format(scores[0][0], scores[0][1], scores[0][2]))\n",
        "print('Reconstructed Image: \\nPSNR: {}\\nMSE: {}\\nSSIM: {}\\n'.format(scores[1][0], scores[1][1], scores[1][2]))\n",
        "\n",
        "\n",
        "# display images as subplots\n",
        "fig, axs = plt.subplots(1, 3, figsize=(20, 8))\n",
        "axs[0].imshow(cv2.cvtColor(ref, cv2.COLOR_BGR2RGB))\n",
        "axs[0].set_title('Original')\n",
        "axs[1].imshow(cv2.cvtColor(degraded, cv2.COLOR_BGR2RGB))\n",
        "axs[1].set_title('Degraded')\n",
        "axs[2].imshow(cv2.cvtColor(output, cv2.COLOR_BGR2RGB))\n",
        "axs[2].set_title('SRCNN')\n",
        "\n",
        "# remove the x and y ticks\n",
        "for ax in axs:\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-dd09f16dc2a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegraded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ML-Image-Super-Resolution-master/images/flowers.bmp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# print all scores for all images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Degraded Image: \\nPSNR: {}\\nMSE: {}\\nSSIM: {}\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reconstructed Image: \\nPSNR: {}\\nMSE: {}\\nSSIM: {}\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-dc8aefa1dbdf>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# preprocess the image with modcrop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mdegraded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegraded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-ccf08f07f0d9>\u001b[0m in \u001b[0;36mmodcrop\u001b[0;34m(img, scale)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtmpsz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmpsz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msz\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "5ylC0Cl4BDKn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "51267f9a-d529-4dc5-a6ee-452b8eac80cd"
      },
      "cell_type": "code",
      "source": [
        "for file in os.listdir('ML-Image-Super-Resolution-master/images'):\n",
        "    \n",
        "    # perform super-resolution\n",
        "    ref, degraded, output, scores = predict('ML-Image-Super-Resolution-master/images/{}'.format(file))\n",
        "    \n",
        "    # display images as subplots\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(20, 8))\n",
        "    axs[0].imshow(cv2.cvtColor(ref, cv2.COLOR_BGR2RGB))\n",
        "    axs[0].set_title('Original')\n",
        "    axs[1].imshow(cv2.cvtColor(degraded, cv2.COLOR_BGR2RGB))\n",
        "    axs[1].set_title('Degraded')\n",
        "    axs[1].set(xlabel = 'PSNR: {}\\nMSE: {} \\nSSIM: {}'.format(scores[0][0], scores[0][1], scores[0][2]))\n",
        "    axs[2].imshow(cv2.cvtColor(output, cv2.COLOR_BGR2RGB))\n",
        "    axs[2].set_title('SRCNN')\n",
        "    axs[2].set(xlabel = 'PSNR: {} \\nMSE: {} \\nSSIM: {}'.format(scores[1][0], scores[1][1], scores[1][2]))\n",
        "\n",
        "    # remove the x and y ticks\n",
        "    for ax in axs:\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "      \n",
        "    print('Saving {}'.format(file))\n",
        "    fig.savefig('output/{}.png'.format(os.path.splitext(file)[0])) \n",
        "    plt.close()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-d1680e504b23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# perform super-resolution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegraded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ML-Image-Super-Resolution-master/images/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# display images as subplots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-dc8aefa1dbdf>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# preprocess the image with modcrop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mdegraded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegraded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-ccf08f07f0d9>\u001b[0m in \u001b[0;36mmodcrop\u001b[0;34m(img, scale)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtmpsz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmpsz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msz\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "THxF2bpNCESW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d11a7420-0f19-47bf-d8b4-47cf2b95bbac"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.jpg\t\t\t\t      Output1.jpg\n",
            "ML-Image-Super-Resolution-master      Output2.jpg\n",
            "ML-Image-Super-Resolution-master.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_Dq03RRxCtC7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}